{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKADPWcFKlj3"
      },
      "source": [
        "# **1. Import Library**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgA3ERnVn84N"
      },
      "source": [
        "Pada tahap ini, Anda perlu mengimpor beberapa pustaka (library) Python yang dibutuhkan untuk analisis data dan pembangunan model machine learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "BlmvjLY9M4Yj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3YIEnAFKrKL"
      },
      "source": [
        "# **2. Memuat Dataset dari Hasil Clustering**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ey3ItwTen_7E"
      },
      "source": [
        "Memuat dataset hasil clustering dari file CSV ke dalam variabel DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "GHCGNTyrM5fS"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionAmount</th>\n",
              "      <th>TransactionType</th>\n",
              "      <th>CustomerAge</th>\n",
              "      <th>CustomerOccupation</th>\n",
              "      <th>LoginAttempts</th>\n",
              "      <th>AccountBalance</th>\n",
              "      <th>Cluster</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.09</td>\n",
              "      <td>Debit</td>\n",
              "      <td>70</td>\n",
              "      <td>Doctor</td>\n",
              "      <td>1</td>\n",
              "      <td>5112.21</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>376.24</td>\n",
              "      <td>Debit</td>\n",
              "      <td>68</td>\n",
              "      <td>Doctor</td>\n",
              "      <td>1</td>\n",
              "      <td>13758.91</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>126.29</td>\n",
              "      <td>Debit</td>\n",
              "      <td>19</td>\n",
              "      <td>Student</td>\n",
              "      <td>1</td>\n",
              "      <td>1122.35</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>184.50</td>\n",
              "      <td>Debit</td>\n",
              "      <td>26</td>\n",
              "      <td>Student</td>\n",
              "      <td>1</td>\n",
              "      <td>8569.06</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13.45</td>\n",
              "      <td>Credit</td>\n",
              "      <td>26</td>\n",
              "      <td>Student</td>\n",
              "      <td>1</td>\n",
              "      <td>7429.40</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2507</th>\n",
              "      <td>856.21</td>\n",
              "      <td>Credit</td>\n",
              "      <td>33</td>\n",
              "      <td>Doctor</td>\n",
              "      <td>1</td>\n",
              "      <td>12690.79</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2508</th>\n",
              "      <td>251.54</td>\n",
              "      <td>Debit</td>\n",
              "      <td>48</td>\n",
              "      <td>Doctor</td>\n",
              "      <td>1</td>\n",
              "      <td>254.75</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2509</th>\n",
              "      <td>28.63</td>\n",
              "      <td>Debit</td>\n",
              "      <td>56</td>\n",
              "      <td>Retired</td>\n",
              "      <td>1</td>\n",
              "      <td>3382.91</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2510</th>\n",
              "      <td>185.97</td>\n",
              "      <td>Debit</td>\n",
              "      <td>23</td>\n",
              "      <td>Student</td>\n",
              "      <td>1</td>\n",
              "      <td>1776.91</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2511</th>\n",
              "      <td>243.08</td>\n",
              "      <td>Credit</td>\n",
              "      <td>24</td>\n",
              "      <td>Student</td>\n",
              "      <td>1</td>\n",
              "      <td>131.25</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2512 rows Ã— 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      TransactionAmount TransactionType  CustomerAge CustomerOccupation  \\\n",
              "0                 14.09           Debit           70             Doctor   \n",
              "1                376.24           Debit           68             Doctor   \n",
              "2                126.29           Debit           19            Student   \n",
              "3                184.50           Debit           26            Student   \n",
              "4                 13.45          Credit           26            Student   \n",
              "...                 ...             ...          ...                ...   \n",
              "2507             856.21          Credit           33             Doctor   \n",
              "2508             251.54           Debit           48             Doctor   \n",
              "2509              28.63           Debit           56            Retired   \n",
              "2510             185.97           Debit           23            Student   \n",
              "2511             243.08          Credit           24            Student   \n",
              "\n",
              "      LoginAttempts  AccountBalance  Cluster  \n",
              "0                 1         5112.21        2  \n",
              "1                 1        13758.91        4  \n",
              "2                 1         1122.35        1  \n",
              "3                 1         8569.06        1  \n",
              "4                 1         7429.40        1  \n",
              "...             ...             ...      ...  \n",
              "2507              1        12690.79        4  \n",
              "2508              1          254.75        2  \n",
              "2509              1         3382.91        3  \n",
              "2510              1         1776.91        1  \n",
              "2511              1          131.25        1  \n",
              "\n",
              "[2512 rows x 7 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('Dataset_Clustering.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionAmount</th>\n",
              "      <th>TransactionType</th>\n",
              "      <th>CustomerAge</th>\n",
              "      <th>CustomerOccupation</th>\n",
              "      <th>LoginAttempts</th>\n",
              "      <th>AccountBalance</th>\n",
              "      <th>Cluster</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.09</td>\n",
              "      <td>1</td>\n",
              "      <td>70</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5112.21</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>376.24</td>\n",
              "      <td>1</td>\n",
              "      <td>68</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>13758.91</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>126.29</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1122.35</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>184.50</td>\n",
              "      <td>1</td>\n",
              "      <td>26</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>8569.06</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13.45</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>7429.40</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2507</th>\n",
              "      <td>856.21</td>\n",
              "      <td>0</td>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>12690.79</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2508</th>\n",
              "      <td>251.54</td>\n",
              "      <td>1</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>254.75</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2509</th>\n",
              "      <td>28.63</td>\n",
              "      <td>1</td>\n",
              "      <td>56</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3382.91</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2510</th>\n",
              "      <td>185.97</td>\n",
              "      <td>1</td>\n",
              "      <td>23</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1776.91</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2511</th>\n",
              "      <td>243.08</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>131.25</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2512 rows Ã— 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      TransactionAmount  TransactionType  CustomerAge  CustomerOccupation  \\\n",
              "0                 14.09                1           70                   0   \n",
              "1                376.24                1           68                   0   \n",
              "2                126.29                1           19                   3   \n",
              "3                184.50                1           26                   3   \n",
              "4                 13.45                0           26                   3   \n",
              "...                 ...              ...          ...                 ...   \n",
              "2507             856.21                0           33                   0   \n",
              "2508             251.54                1           48                   0   \n",
              "2509              28.63                1           56                   2   \n",
              "2510             185.97                1           23                   3   \n",
              "2511             243.08                0           24                   3   \n",
              "\n",
              "      LoginAttempts  AccountBalance  Cluster  \n",
              "0                 1         5112.21        2  \n",
              "1                 1        13758.91        4  \n",
              "2                 1         1122.35        1  \n",
              "3                 1         8569.06        1  \n",
              "4                 1         7429.40        1  \n",
              "...             ...             ...      ...  \n",
              "2507              1        12690.79        4  \n",
              "2508              1          254.75        2  \n",
              "2509              1         3382.91        3  \n",
              "2510              1         1776.91        1  \n",
              "2511              1          131.25        1  \n",
              "\n",
              "[2512 rows x 7 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Encode 'TransactionType' dan 'CustomerOccupation'\n",
        "df['TransactionType'] = label_encoder.fit_transform(df['TransactionType'])\n",
        "df['CustomerOccupation'] = label_encoder.fit_transform(df['CustomerOccupation'])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkPem5eWL2UP"
      },
      "source": [
        "# **3. Data Splitting**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYj1rl_JNI9Y"
      },
      "source": [
        "Tahap Data Splitting bertujuan untuk memisahkan dataset menjadi dua bagian: data latih (training set) dan data uji (test set)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "OubAW-7ONKVj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training data size: (2009, 6)\n",
            "Testing data size: (503, 6)\n"
          ]
        }
      ],
      "source": [
        "# Pisahkan fitur dan target\n",
        "X = df.drop('Cluster', axis=1)  # 'Cluster' adalah kolom target\n",
        "y = df['Cluster']  # Target kita adalah 'Cluster'\n",
        "\n",
        "# Split data menjadi training dan testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Cek ukuran data latih dan uji\n",
        "print(f\"Training data size: {X_train.shape}\")\n",
        "print(f\"Testing data size: {X_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVPbB03CMhTT"
      },
      "source": [
        "# **4. Membangun Model Klasifikasi**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ned1pL9zMmBK"
      },
      "source": [
        "## **a. Membangun Model Klasifikasi**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAWzPOE4Nkti"
      },
      "source": [
        "Setelah memilih algoritma klasifikasi yang sesuai, langkah selanjutnya adalah melatih model menggunakan data latih.\n",
        "\n",
        "Berikut adalah rekomendasi tahapannya.\n",
        "1. Pilih algoritma klasifikasi yang sesuai, seperti Logistic Regression, Decision Tree, Random Forest, atau K-Nearest Neighbors (KNN).\n",
        "2. Latih model menggunakan data latih."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "4JYxBe87NLDk"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"â–¸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"â–¾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              feature_weights=None, gamma=None, grow_policy=None,\n",
              "              importance_type=None, interaction_constraints=None,\n",
              "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
              "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
              "              max_leaves=None, min_child_weight=None, missing=nan,\n",
              "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
              "              n_jobs=None, num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              feature_weights=None, gamma=None, grow_policy=None,\n",
              "              importance_type=None, interaction_constraints=None,\n",
              "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
              "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
              "              max_leaves=None, min_child_weight=None, missing=nan,\n",
              "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
              "              n_jobs=None, num_parallel_tree=None, ...)</pre></div> </div></div></div></div>"
            ],
            "text/plain": [
              "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              feature_weights=None, gamma=None, grow_policy=None,\n",
              "              importance_type=None, interaction_constraints=None,\n",
              "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
              "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
              "              max_leaves=None, min_child_weight=None, missing=nan,\n",
              "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
              "              n_jobs=None, num_parallel_tree=None, ...)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Inisialisasi model\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "xgb_model = XGBClassifier(random_state=42)\n",
        "\n",
        "# Latih model\n",
        "rf_model.fit(X_train, y_train)\n",
        "xgb_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seYoHNY3XU1y"
      },
      "source": [
        "**Insight**\n",
        "- Disini saya menggunakan Random Forest dan XGBoost untuk membandingkan kedua metode klasifikasi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ergzChZFEL-O"
      },
      "source": [
        "## **b. Evaluasi Model Klasifikasi**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOm68u-7NpLT"
      },
      "source": [
        "Berikut adalah **rekomendasi** tahapannya.\n",
        "1. Lakukan prediksi menggunakan data uji.\n",
        "2. Hitung metrik evaluasi seperti Accuracy dan F1-Score (Opsional: Precision dan Recall).\n",
        "3. Buat confusion matrix untuk melihat detail prediksi benar dan salah."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "tMq4QAssNLip"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest Accuracy: 1.0\n",
            "Random Forest Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       112\n",
            "           1       1.00      1.00      1.00       129\n",
            "           2       1.00      1.00      1.00        49\n",
            "           3       1.00      1.00      1.00       138\n",
            "           4       1.00      1.00      1.00        75\n",
            "\n",
            "    accuracy                           1.00       503\n",
            "   macro avg       1.00      1.00      1.00       503\n",
            "weighted avg       1.00      1.00      1.00       503\n",
            "\n",
            "Random Forest Confusion Matrix:\n",
            "[[112   0   0   0   0]\n",
            " [  0 129   0   0   0]\n",
            " [  0   0  49   0   0]\n",
            " [  0   0   0 138   0]\n",
            " [  0   0   0   0  75]]\n",
            "XGBoost Accuracy: 0.9980119284294234\n",
            "XGBoost Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       112\n",
            "           1       1.00      1.00      1.00       129\n",
            "           2       1.00      0.98      0.99        49\n",
            "           3       1.00      1.00      1.00       138\n",
            "           4       0.99      1.00      0.99        75\n",
            "\n",
            "    accuracy                           1.00       503\n",
            "   macro avg       1.00      1.00      1.00       503\n",
            "weighted avg       1.00      1.00      1.00       503\n",
            "\n",
            "XGBoost Confusion Matrix:\n",
            "[[112   0   0   0   0]\n",
            " [  0 129   0   0   0]\n",
            " [  0   0  48   0   1]\n",
            " [  0   0   0 138   0]\n",
            " [  0   0   0   0  75]]\n"
          ]
        }
      ],
      "source": [
        "# Prediksi dengan Random Forest\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
        "print(\"Random Forest Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "print(\"Random Forest Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_rf))\n",
        "\n",
        "# Prediksi dengan XGBoost\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "print(\"XGBoost Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n",
        "print(\"XGBoost Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_xgb))\n",
        "print(\"XGBoost Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_xgb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4_9OwrsXZlz"
      },
      "source": [
        "**Insight**\n",
        "-  Pada metode **Random Forest** maupun **XGBoost** menunjukkan akurasi hampir menyuentuh **100%**, yang menandakan model mengalami overfitting.  \n",
        "Hal ini terlihat dari confusion matrix, di mana model tidak melakukan kesalahan sama sekali pada data uji.  \n",
        "- Kemungkinan penyebabnya adalah kompleksitas model yang terlalu tinggi, data leakage, atau jumlah data yang terbatas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ph9yIYDXEPuB"
      },
      "source": [
        "## **c. Tuning Model Klasifikasi (Optional)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Bikx3LINv5e"
      },
      "source": [
        "Gunakan GridSearchCV, RandomizedSearchCV, atau metode lainnya untuk mencari kombinasi hyperparameter terbaik"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "winbFzb8NL95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
            "[CV] END criterion=gini, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=40; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=40; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=40; total time=   0.1s\n",
            "[CV] END criterion=entropy, max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
            "[CV] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=40; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
            "[CV] END criterion=entropy, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=90; total time=   0.3s\n",
            "[CV] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=40; total time=   0.1s\n",
            "[CV] END criterion=entropy, max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
            "[CV] END criterion=entropy, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=90; total time=   0.3s\n",
            "[CV] END criterion=entropy, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=90; total time=   0.3s\n",
            "[CV] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=40; total time=   0.1s\n",
            "[CV] END criterion=entropy, max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=40; total time=   0.1s\n",
            "[CV] END criterion=entropy, max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=40; total time=   0.1s\n",
            "[CV] END criterion=entropy, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=140; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=140; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=140; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=60; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=60; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=40; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=60; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=90; total time=   0.4s\n",
            "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=190; total time=   0.6s\n",
            "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=190; total time=   0.7s\n",
            "[CV] END criterion=gini, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=90; total time=   0.4s\n",
            "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=190; total time=   0.8s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=20; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=20; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=90; total time=   0.4s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=20; total time=   0.1s\n",
            "[CV] END criterion=entropy, max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=190; total time=   0.6s\n",
            "[CV] END criterion=gini, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=80; total time=   0.3s\n",
            "[CV] END criterion=entropy, max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=190; total time=   0.8s\n",
            "[CV] END criterion=gini, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=190; total time=   0.6s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=80; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=190; total time=   0.7s\n",
            "[CV] END criterion=gini, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=80; total time=   0.3s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=80; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=170; total time=   0.5s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=150; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=80; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=150; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=150; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=30; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=30; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=30; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=40; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=40; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=170; total time=   0.6s\n",
            "[CV] END criterion=entropy, max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=190; total time=   0.6s\n",
            "[CV] END criterion=gini, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=80; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=20; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=90; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=90; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=40; total time=   0.1s\n",
            "[CV] END criterion=entropy, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=20; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=90; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=20; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=20; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=20; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=190; total time=   0.5s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=20; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=190; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=190; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=190; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=90; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=90; total time=   0.3s\n",
            "[CV] END criterion=gini, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=170; total time=   0.5s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=90; total time=   0.3s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=90; total time=   0.3s\n",
            "[CV] END criterion=gini, max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=90; total time=   0.3s\n",
            "[CV] END criterion=gini, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=170; total time=   0.5s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=90; total time=   0.3s\n",
            "[CV] END criterion=gini, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=170; total time=   0.5s\n",
            "[CV] END criterion=entropy, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=180; total time=   0.6s\n",
            "[CV] END criterion=gini, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=180; total time=   0.6s\n",
            "[CV] END criterion=entropy, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=80; total time=   0.3s\n",
            "[CV] END criterion=gini, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=180; total time=   0.6s\n",
            "[CV] END criterion=entropy, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=150; total time=   0.5s\n",
            "[CV] END criterion=entropy, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=80; total time=   0.3s\n",
            "[CV] END criterion=gini, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=180; total time=   0.7s\n",
            "[CV] END criterion=gini, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=170; total time=   0.6s\n",
            "[CV] END criterion=entropy, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=80; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=110; total time=   0.3s\n",
            "[CV] END criterion=entropy, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=30; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=30; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=30; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=180; total time=   0.5s\n",
            "[CV] END criterion=entropy, max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=110; total time=   0.4s\n",
            "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=70; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=180; total time=   0.6s\n",
            "[CV] END criterion=entropy, max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=110; total time=   0.3s\n",
            "[CV] END criterion=entropy, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=150; total time=   0.6s\n",
            "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=70; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=150; total time=   0.5s\n",
            "[CV] END criterion=entropy, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=150; total time=   0.5s\n",
            "[CV] END criterion=entropy, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=30; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=70; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=30; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=60; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=130; total time=   0.4s\n",
            "[CV] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=60; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=150; total time=   0.5s\n",
            "[CV] END criterion=entropy, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=130; total time=   0.4s\n",
            "[CV] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=60; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=150; total time=   0.5s\n",
            "[CV] END criterion=entropy, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=30; total time=   0.1s\n",
            "[CV] END criterion=entropy, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=70; total time=   0.3s\n",
            "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=70; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=150; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=150; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=130; total time=   0.4s\n",
            "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=70; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=180; total time=   0.5s\n",
            "[CV] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=20; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=20; total time=   0.1s\n",
            "[CV] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=110; total time=   0.3s\n",
            "[CV] END criterion=entropy, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=180; total time=   0.5s\n",
            "[CV] END criterion=entropy, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=20; total time=   0.1s\n",
            "[CV] END criterion=entropy, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=170; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=170; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=110; total time=   0.4s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=150; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=170; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=140; total time=   0.4s\n",
            "[CV] END criterion=gini, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=140; total time=   0.4s\n",
            "[CV] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=110; total time=   0.3s\n",
            "[CV] END criterion=entropy, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=70; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=150; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=150; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
            "[CV] END criterion=entropy, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=150; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=60; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
            "[CV] END criterion=gini, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=60; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=60; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=180; total time=   0.5s\n",
            "[CV] END criterion=gini, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=170; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=170; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=170; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=70; total time=   0.3s\n",
            "[CV] END criterion=entropy, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=70; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=140; total time=   0.4s\n",
            "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=130; total time=   0.4s\n",
            "[CV] END criterion=gini, max_depth=30, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=180; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=30, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=180; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
            "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=130; total time=   0.5s\n",
            "[CV] END criterion=entropy, max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=170; total time=   0.5s\n",
            "[CV] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=160; total time=   0.5s\n",
            "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=130; total time=   0.4s\n",
            "[CV] END criterion=gini, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=190; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=190; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=190; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=180; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=160; total time=   0.5s\n",
            "[CV] END criterion=gini, max_depth=30, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=180; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=180; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=180; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=170; total time=   0.6s\n",
            "[CV] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=150; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=150; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=190; total time=   0.6s\n",
            "[CV] END criterion=entropy, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=190; total time=   0.6s\n",
            "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=150; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
            "[CV] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=160; total time=   0.5s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=60; total time=   0.3s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=60; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=170; total time=   0.5s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=20; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=60; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=20; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=120; total time=   0.3s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=20; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=120; total time=   0.4s\n",
            "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=80; total time=   0.4s\n",
            "[CV] END criterion=entropy, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=190; total time=   0.7s\n",
            "[CV] END criterion=entropy, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=180; total time=   0.7s\n",
            "[CV] END criterion=gini, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=120; total time=   0.3s\n",
            "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=80; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=120; total time=   0.4s\n",
            "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=80; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=160; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=160; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=180; total time=   0.7s\n",
            "[CV] END criterion=entropy, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=160; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=120; total time=   0.4s\n",
            "[CV] END criterion=entropy, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=90; total time=   0.3s\n",
            "[CV] END criterion=entropy, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=90; total time=   0.3s\n",
            "[CV] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=70; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.1s\n",
            "[CV] END criterion=entropy, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=120; total time=   0.3s\n",
            "[CV] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=70; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=70; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=180; total time=   0.6s\n",
            "[CV] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=70; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=90; total time=   0.3s\n",
            "[CV] END criterion=entropy, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=70; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=70; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=70; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=70; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=70; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=70; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=130; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=130; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=30, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=30, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=30, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=70; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=30; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=30; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=30; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=150; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=150; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=150; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=150; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=150; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
            "[CV] END criterion=entropy, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=130; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=150; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
            "[CV] END criterion=gini, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=120; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=150; total time=   0.6s\n",
            "[CV] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=150; total time=   0.5s\n",
            "[CV] END criterion=entropy, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=70; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=120; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=120; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=120; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=120; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
            "[CV] END criterion=gini, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=120; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
            "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=10; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=40; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=40; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=40; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
            "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
            "[CV] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=150; total time=   0.4s\n",
            "[CV] END criterion=entropy, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=140; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=140; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=140; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=160; total time=   0.5s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=80; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=160; total time=   0.5s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=80; total time=   0.3s\n",
            "[CV] END criterion=gini, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=160; total time=   0.4s\n",
            "[CV] END criterion=gini, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=160; total time=   0.5s\n",
            "[CV] END criterion=entropy, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=190; total time=   0.6s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=80; total time=   0.3s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=160; total time=   0.4s\n",
            "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
            "[CV] END criterion=gini, max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=160; total time=   0.5s\n",
            "[CV] END criterion=gini, max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=160; total time=   0.4s\n",
            "[CV] END criterion=entropy, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=170; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=170; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=170; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=190; total time=   0.6s\n",
            "[CV] END criterion=gini, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=160; total time=   0.5s\n",
            "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
            "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
            "[CV] END criterion=entropy, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=190; total time=   0.6s\n",
            "[CV] END criterion=gini, max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=160; total time=   0.4s\n",
            "[CV] END criterion=gini, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=160; total time=   0.4s\n",
            "[CV] END criterion=gini, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=160; total time=   0.5s\n",
            "[CV] END criterion=gini, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=160; total time=   0.5s\n",
            "[CV] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=190; total time=   0.5s\n",
            "[CV] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=190; total time=   0.4s\n",
            "[CV] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=190; total time=   0.5s\n",
            "Best Random Forest Params: {'n_estimators': np.int64(40), 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 20, 'criterion': 'gini'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ldzorph/code/machine-learning-dbs/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
            "102 fits failed out of a total of 300.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "49 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ldzorph/code/machine-learning-dbs/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/home/ldzorph/code/machine-learning-dbs/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/home/ldzorph/code/machine-learning-dbs/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/home/ldzorph/code/machine-learning-dbs/.venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "53 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ldzorph/code/machine-learning-dbs/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/home/ldzorph/code/machine-learning-dbs/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/home/ldzorph/code/machine-learning-dbs/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/home/ldzorph/code/machine-learning-dbs/.venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/home/ldzorph/code/machine-learning-dbs/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [1.         1.         1.         1.         1.         1.\n",
            " 1.         1.                nan 1.         1.         1.\n",
            " 1.         1.         1.         1.                nan        nan\n",
            " 1.                nan 1.         1.                nan 1.\n",
            "        nan 1.         1.         1.         0.99950249        nan\n",
            " 1.         1.                nan 1.         1.         1.\n",
            " 1.         1.         1.                nan 1.                nan\n",
            "        nan 1.         1.                nan        nan 1.\n",
            " 1.         1.                nan        nan        nan 1.\n",
            " 1.                nan 1.         1.                nan        nan\n",
            " 1.                nan 1.         1.         1.         1.\n",
            " 1.         1.                nan 1.                nan 0.99950249\n",
            " 1.         1.         0.99900498 1.         1.                nan\n",
            " 1.                nan        nan 1.                nan        nan\n",
            "        nan        nan        nan 1.         1.         1.\n",
            "        nan 1.         1.                nan        nan 1.\n",
            " 1.                nan 1.         1.        ]\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "param_dist_rf = {\n",
        "    'n_estimators': np.arange(10, 200, 10),\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['auto', 'sqrt', 'log2'],\n",
        "    'criterion': ['gini', 'entropy']\n",
        "}\n",
        "\n",
        "random_search_rf = RandomizedSearchCV(estimator=rf_model, param_distributions=param_dist_rf, n_iter=100, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
        "random_search_rf.fit(X_train, y_train)\n",
        "\n",
        "best_rf_model = random_search_rf.best_estimator_\n",
        "print(f\"Best Random Forest Params: {random_search_rf.best_params_}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=110, subsample=0.9; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=110, subsample=0.9; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, min_child_weight=5, n_estimators=70, subsample=1; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, min_child_weight=5, n_estimators=70, subsample=1; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=110, subsample=0.9; total time=   0.2s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=170, subsample=1; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, min_child_weight=5, n_estimators=70, subsample=1; total time=   0.1s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=170, subsample=1; total time=   0.2s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=170, subsample=1; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, min_child_weight=5, n_estimators=60, subsample=0.7; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, min_child_weight=5, n_estimators=60, subsample=0.7; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, min_child_weight=5, n_estimators=60, subsample=0.7; total time=   0.1s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=120, subsample=1; total time=   0.2s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=120, subsample=1; total time=   0.1s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=120, subsample=1; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=160, subsample=1; total time=   0.2s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=10, min_child_weight=1, n_estimators=50, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1; total time=   0.1s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=70, subsample=0.7; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=160, subsample=1; total time=   0.3s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=10, min_child_weight=1, n_estimators=50, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, min_child_weight=1, n_estimators=110, subsample=1; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=170, subsample=0.9; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=170, subsample=0.9; total time=   0.2s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=70, subsample=0.7; total time=   0.1s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=70, subsample=0.7; total time=   0.1s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=10, min_child_weight=1, n_estimators=50, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=50, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=50, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, min_child_weight=1, n_estimators=110, subsample=1; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, min_child_weight=5, n_estimators=60, subsample=0.7; total time=   0.1s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=50, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=160, subsample=1; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, min_child_weight=5, n_estimators=60, subsample=0.7; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, min_child_weight=1, n_estimators=110, subsample=1; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, min_child_weight=5, n_estimators=60, subsample=0.7; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, min_child_weight=5, n_estimators=70, subsample=1; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=170, subsample=0.9; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=90, subsample=1; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, min_child_weight=3, n_estimators=180, subsample=0.7; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, min_child_weight=3, n_estimators=180, subsample=0.7; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, min_child_weight=5, n_estimators=70, subsample=1; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, min_child_weight=5, n_estimators=70, subsample=1; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=90, subsample=1; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=110, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=90, subsample=1; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, min_child_weight=3, n_estimators=180, subsample=0.7; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=160, subsample=0.8; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=160, subsample=0.8; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=110, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=10, min_child_weight=5, n_estimators=100, subsample=0.9; total time=   0.1s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=180, subsample=1; total time=   0.3s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=10, min_child_weight=5, n_estimators=100, subsample=0.9; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=110, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=180, subsample=1; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.7; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.7; total time=   0.1s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=10, min_child_weight=5, n_estimators=100, subsample=0.9; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=6, min_child_weight=3, n_estimators=190, subsample=0.8; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, min_child_weight=5, n_estimators=80, subsample=0.7; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.7; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, min_child_weight=5, n_estimators=80, subsample=0.7; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=160, subsample=0.8; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, min_child_weight=5, n_estimators=80, subsample=0.7; total time=   0.1s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=180, subsample=1; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=100, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=6, min_child_weight=3, n_estimators=190, subsample=0.8; total time=   0.3s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, min_child_weight=1, n_estimators=110, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=170, subsample=1; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=100, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=100, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=170, subsample=1; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=6, min_child_weight=3, n_estimators=190, subsample=0.8; total time=   0.3s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, min_child_weight=1, n_estimators=110, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=150, subsample=0.7; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=60, subsample=0.9; total time=   0.1s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, min_child_weight=1, n_estimators=110, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=150, subsample=0.7; total time=   0.2s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=70, subsample=0.9; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=60, subsample=0.9; total time=   0.1s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=170, subsample=1; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=60, subsample=0.9; total time=   0.1s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=70, subsample=0.9; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=150, subsample=0.7; total time=   0.2s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=50, subsample=1; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, min_child_weight=3, n_estimators=150, subsample=1; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, min_child_weight=1, n_estimators=70, subsample=0.7; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, min_child_weight=1, n_estimators=70, subsample=0.7; total time=   0.2s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=50, subsample=1; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=80, subsample=1; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, min_child_weight=3, n_estimators=150, subsample=1; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=80, subsample=1; total time=   0.1s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=50, subsample=1; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=70, subsample=0.7; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=80, subsample=1; total time=   0.1s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=70, subsample=0.9; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=70, subsample=0.7; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, min_child_weight=1, n_estimators=70, subsample=0.7; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=70, subsample=0.7; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, min_child_weight=3, n_estimators=150, subsample=1; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, min_child_weight=5, n_estimators=170, subsample=0.9; total time=   0.3s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=80, subsample=0.7; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, min_child_weight=1, n_estimators=170, subsample=0.9; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, min_child_weight=3, n_estimators=110, subsample=1; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, min_child_weight=5, n_estimators=170, subsample=0.9; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, min_child_weight=3, n_estimators=110, subsample=1; total time=   0.1s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=80, subsample=0.7; total time=   0.1s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=180, subsample=1; total time=   0.3s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=180, subsample=1; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=10, min_child_weight=3, n_estimators=110, subsample=0.7; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, min_child_weight=3, n_estimators=110, subsample=1; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=10, min_child_weight=3, n_estimators=110, subsample=0.7; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, min_child_weight=1, n_estimators=170, subsample=0.9; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, min_child_weight=5, n_estimators=170, subsample=0.9; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, min_child_weight=1, n_estimators=170, subsample=0.9; total time=   0.2s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=80, subsample=0.7; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=6, min_child_weight=3, n_estimators=120, subsample=1; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=10, min_child_weight=3, n_estimators=110, subsample=0.7; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=80, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=6, min_child_weight=3, n_estimators=120, subsample=1; total time=   0.1s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=180, subsample=1; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=80, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=80, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=10, min_child_weight=3, n_estimators=50, subsample=1; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=6, min_child_weight=3, n_estimators=120, subsample=1; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=80, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=10, min_child_weight=3, n_estimators=50, subsample=1; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=80, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=80, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=10, min_child_weight=3, n_estimators=50, subsample=1; total time=   0.1s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=150, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=10, min_child_weight=3, n_estimators=110, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=150, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, min_child_weight=3, n_estimators=150, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, min_child_weight=3, n_estimators=150, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=130, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=150, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=140, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=10, min_child_weight=3, n_estimators=110, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=140, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, min_child_weight=3, n_estimators=150, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=10, min_child_weight=3, n_estimators=110, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=130, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=130, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=6, min_child_weight=3, n_estimators=180, subsample=0.9; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=140, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=10, min_child_weight=5, n_estimators=50, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=6, min_child_weight=3, n_estimators=180, subsample=0.9; total time=   0.2s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=10, min_child_weight=5, n_estimators=50, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=10, min_child_weight=5, n_estimators=50, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=90, subsample=0.7; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=6, min_child_weight=3, n_estimators=180, subsample=0.9; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, subsample=1; total time=   0.1s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=10, min_child_weight=5, n_estimators=160, subsample=0.7; total time=   0.2s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=10, min_child_weight=5, n_estimators=160, subsample=0.7; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, subsample=1; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=70, subsample=0.9; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=90, subsample=0.7; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=70, subsample=0.9; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, min_child_weight=1, n_estimators=180, subsample=0.9; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, subsample=1; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=70, subsample=0.9; total time=   0.1s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=10, min_child_weight=5, n_estimators=160, subsample=0.7; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, min_child_weight=1, n_estimators=180, subsample=0.9; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, min_child_weight=3, n_estimators=100, subsample=1; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, min_child_weight=5, n_estimators=70, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, min_child_weight=5, n_estimators=70, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=10, min_child_weight=5, n_estimators=60, subsample=0.9; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, min_child_weight=3, n_estimators=100, subsample=1; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, min_child_weight=5, n_estimators=180, subsample=1; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=10, min_child_weight=5, n_estimators=60, subsample=0.9; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=90, subsample=0.7; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=10, min_child_weight=5, n_estimators=60, subsample=0.9; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, min_child_weight=5, n_estimators=70, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, min_child_weight=3, n_estimators=100, subsample=1; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, min_child_weight=5, n_estimators=180, subsample=1; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, min_child_weight=5, n_estimators=180, subsample=1; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=110, subsample=0.7; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=150, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, min_child_weight=1, n_estimators=180, subsample=0.9; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=150, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=110, subsample=0.7; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=110, subsample=0.7; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, min_child_weight=5, n_estimators=150, subsample=0.7; total time=   0.2s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=180, subsample=0.8; total time=   0.3s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=180, subsample=0.8; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=110, subsample=0.7; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=150, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=110, subsample=0.7; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=110, subsample=0.7; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, min_child_weight=5, n_estimators=150, subsample=0.7; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, min_child_weight=5, n_estimators=150, subsample=0.7; total time=   0.2s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=10, min_child_weight=3, n_estimators=180, subsample=1; total time=   0.2s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=10, min_child_weight=3, n_estimators=180, subsample=1; total time=   0.2s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=180, subsample=0.8; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=160, subsample=1; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=160, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=80, subsample=1; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=160, subsample=1; total time=   0.3s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=190, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=190, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=90, subsample=0.9; total time=   0.1s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=10, min_child_weight=3, n_estimators=180, subsample=1; total time=   0.2s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=80, subsample=1; total time=   0.1s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=80, subsample=1; total time=   0.1s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=190, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=160, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=160, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=6, min_child_weight=5, n_estimators=100, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=90, subsample=0.9; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=90, subsample=0.9; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=50, subsample=0.7; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=160, subsample=1; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, min_child_weight=5, n_estimators=120, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=6, min_child_weight=5, n_estimators=100, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, min_child_weight=5, n_estimators=120, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=6, min_child_weight=5, n_estimators=100, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=50, subsample=0.7; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=140, subsample=0.7; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=50, subsample=0.7; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=140, subsample=0.7; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=80, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=80, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, min_child_weight=5, n_estimators=120, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=60, subsample=1; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=190, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=80, subsample=0.8; total time=   0.1s[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=190, subsample=0.8; total time=   0.2s\n",
            "\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=60, subsample=1; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=60, subsample=1; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=140, subsample=0.7; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=6, min_child_weight=3, n_estimators=190, subsample=0.7; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=190, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=6, min_child_weight=3, n_estimators=190, subsample=0.7; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=190, subsample=0.9; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=190, subsample=0.9; total time=   0.2s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=180, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=170, subsample=0.9; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, min_child_weight=5, n_estimators=80, subsample=1; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=170, subsample=0.9; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, min_child_weight=1, n_estimators=170, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=180, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, min_child_weight=1, n_estimators=170, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, min_child_weight=5, n_estimators=80, subsample=1; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=6, min_child_weight=3, n_estimators=190, subsample=0.7; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=190, subsample=0.9; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=3, min_child_weight=5, n_estimators=80, subsample=1; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, min_child_weight=5, n_estimators=50, subsample=0.7; total time=   0.1s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=180, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, min_child_weight=5, n_estimators=50, subsample=0.7; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, min_child_weight=1, n_estimators=170, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, min_child_weight=5, n_estimators=90, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, min_child_weight=5, n_estimators=160, subsample=0.9; total time=   0.1s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, min_child_weight=5, n_estimators=90, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, min_child_weight=5, n_estimators=50, subsample=0.7; total time=   0.1s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, min_child_weight=5, n_estimators=90, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, min_child_weight=5, n_estimators=160, subsample=0.9; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=170, subsample=0.9; total time=   0.4s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, min_child_weight=5, n_estimators=160, subsample=0.9; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=130, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=130, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, min_child_weight=5, n_estimators=70, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=6, min_child_weight=3, n_estimators=160, subsample=1; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=6, min_child_weight=5, n_estimators=70, subsample=1; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=6, min_child_weight=3, n_estimators=160, subsample=1; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=130, subsample=0.9; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=6, min_child_weight=5, n_estimators=70, subsample=1; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, min_child_weight=5, n_estimators=70, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, min_child_weight=5, n_estimators=70, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=130, subsample=0.9; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=130, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=120, subsample=0.9; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.3, max_depth=6, min_child_weight=5, n_estimators=70, subsample=1; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=10, min_child_weight=5, n_estimators=100, subsample=1; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=6, min_child_weight=3, n_estimators=160, subsample=1; total time=   0.2s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=120, subsample=0.9; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=130, subsample=0.9; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=10, min_child_weight=5, n_estimators=100, subsample=1; total time=   0.1s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=10, min_child_weight=5, n_estimators=140, subsample=1; total time=   0.2s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=120, subsample=0.9; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, min_child_weight=3, n_estimators=50, subsample=0.7; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, min_child_weight=3, n_estimators=50, subsample=0.7; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=10, min_child_weight=5, n_estimators=100, subsample=1; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=120, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=120, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=10, min_child_weight=5, n_estimators=140, subsample=1; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, min_child_weight=3, n_estimators=50, subsample=0.7; total time=   0.1s\n",
            "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=10, min_child_weight=5, n_estimators=140, subsample=1; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=100, subsample=1; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=100, subsample=1; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=60, subsample=0.7; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=120, subsample=0.8; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=60, subsample=0.7; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=60, subsample=0.7; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=10, min_child_weight=3, n_estimators=80, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=100, subsample=1; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=10, min_child_weight=3, n_estimators=80, subsample=0.8; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=10, min_child_weight=3, n_estimators=80, subsample=0.8; total time=   0.1s\n",
            "Best XGBoost Params: {'subsample': 0.9, 'n_estimators': np.int64(110), 'min_child_weight': 1, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.8}\n"
          ]
        }
      ],
      "source": [
        "param_dist_xgb = {\n",
        "    'n_estimators': np.arange(50, 200, 10),\n",
        "    'max_depth': [3, 6, 10],\n",
        "    'min_child_weight': [1, 3, 5],\n",
        "    'learning_rate': [0.01, 0.1, 0.3],\n",
        "    'subsample': [0.7, 0.8, 0.9, 1],\n",
        "    'colsample_bytree': [0.7, 0.8, 1]\n",
        "}\n",
        "\n",
        "random_search_xgb = RandomizedSearchCV(estimator=xgb_model, param_distributions=param_dist_xgb, n_iter=100, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
        "random_search_xgb.fit(X_train, y_train)\n",
        "\n",
        "best_xgb_model = random_search_xgb.best_estimator_\n",
        "print(f\"Best XGBoost Params: {random_search_xgb.best_params_}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hE7pqlEPEYzI"
      },
      "source": [
        "## **d. Evaluasi Model Klasifikasi setelah Tuning (Optional)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feaPESoeN0zz"
      },
      "source": [
        "Berikut adalah rekomendasi tahapannya.\n",
        "1. Gunakan model dengan hyperparameter terbaik.\n",
        "2. Hitung ulang metrik evaluasi untuk melihat apakah ada peningkatan performa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "HTXZRvEeNMb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest Accuracy: 1.0\n",
            "Random Forest Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       112\n",
            "           1       1.00      1.00      1.00       129\n",
            "           2       1.00      1.00      1.00        49\n",
            "           3       1.00      1.00      1.00       138\n",
            "           4       1.00      1.00      1.00        75\n",
            "\n",
            "    accuracy                           1.00       503\n",
            "   macro avg       1.00      1.00      1.00       503\n",
            "weighted avg       1.00      1.00      1.00       503\n",
            "\n",
            "Random Forest Confusion Matrix:\n",
            "[[112   0   0   0   0]\n",
            " [  0 129   0   0   0]\n",
            " [  0   0  49   0   0]\n",
            " [  0   0   0 138   0]\n",
            " [  0   0   0   0  75]]\n",
            "XGBoost Accuracy: 0.9980119284294234\n",
            "XGBoost Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       112\n",
            "           1       1.00      1.00      1.00       129\n",
            "           2       1.00      0.98      0.99        49\n",
            "           3       1.00      1.00      1.00       138\n",
            "           4       0.99      1.00      0.99        75\n",
            "\n",
            "    accuracy                           1.00       503\n",
            "   macro avg       1.00      1.00      1.00       503\n",
            "weighted avg       1.00      1.00      1.00       503\n",
            "\n",
            "XGBoost Confusion Matrix:\n",
            "[[112   0   0   0   0]\n",
            " [  0 129   0   0   0]\n",
            " [  0   0  48   0   1]\n",
            " [  0   0   0 138   0]\n",
            " [  0   0   0   0  75]]\n"
          ]
        }
      ],
      "source": [
        "# Prediksi dengan Random Forest dengan best params\n",
        "y_pred_rf = best_rf_model.predict(X_test)\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
        "print(\"Random Forest Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "print(\"Random Forest Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_rf))\n",
        "\n",
        "# Prediksi dengan XGBoost dengan best params\n",
        "y_pred_xgb = best_xgb_model.predict(X_test)\n",
        "print(\"XGBoost Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n",
        "print(\"XGBoost Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_xgb))\n",
        "print(\"XGBoost Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_xgb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRsOdm4uEgAW"
      },
      "source": [
        "## **e. Analisis Hasil Evaluasi Model Klasifikasi**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hm3BhSi6N4_l"
      },
      "source": [
        "Berikut adalah **rekomendasi** tahapannya.\n",
        "1. Bandingkan hasil evaluasi sebelum dan setelah tuning (jika dilakukan).\n",
        "2. Identifikasi kelemahan model, seperti:\n",
        "  - Precision atau Recall rendah untuk kelas tertentu.\n",
        "  - Apakah model mengalami overfitting atau underfitting?\n",
        "3. Berikan rekomendasi tindakan lanjutan, seperti mengumpulkan data tambahan atau mencoba algoritma lain jika hasil belum memuaskan."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest Cross-Validation Accuracy: 1.0000 +/- 0.0000\n",
            "XGBoost Cross-Validation Accuracy: 0.9995 +/- 0.0010\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2gAAAHWCAYAAAACSaoRAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAhVRJREFUeJzs3Xd8Tfcfx/FXEtnLCoKILbaKFWq1KkUH1VIdRqsTpZTSaqkOpa1SVHXooIoOdP2oGrG32JsakQRFQkTm+f1x5XIrIYkk5yZ5Px+P+8hx7vec+77nd+qXj8853+NgGIaBiIiIiIiImM7R7AAiIiIiIiJioQJNRERERETETqhAExERERERsRMq0EREREREROyECjQRERERERE7oQJNRERERETETqhAExERERERsRMq0EREREREROyECjQRERERERE7oQJNRERyRO/evalYsaLNOgcHB0aPHn3LbUePHo2Dg0OO5lmxYgUODg6sWLEiR/crkh1t2rShTZs2txyn81ZEVKCJiGTD4cOHee6556hcuTJubm74+PjQokULJk2aRHx8vNnxbmrr1q04ODgwcuTIDMccPHgQBwcHBg8enIfJsufTTz/lm2++MTtGhpo0aYKDgwPTpk0zO4pkUZs2bXBwcEj3tW/fPrPjiUgBVcTsACIi+c0ff/zBI488gqurKz179qROnTokJiayevVqhg4dyu7du/n888/Njpmhhg0bEhQUxA8//MA777yT7pjZs2cD8MQTT9zWZ8XHx1OkSO7+X82nn35KyZIl6d27t836Vq1aER8fj4uLS65+/s0cPHiQTZs2UbFiRb7//nteeOEF07JI9pQvX56xY8fesL5s2bImpBGRwkAFmohIFhw9epRHH32UwMBAli1bhr+/v/W9fv36cejQIf74448Mt09NTSUxMRE3N7e8iJuhxx9/nDfeeIP169fTrFmzG97/4YcfCAoKomHDhrf1OWZ+T0dHR9OP86xZsyhVqhQfffQRDz/8MP/8888Nl4HaA3s5L/NaZr63r6/vbf9DhYhIVugSRxGRLBg/fjyXLl3iq6++sinO0lStWpWBAwda/+zg4ED//v35/vvvqV27Nq6urixatAiAbdu20aFDB3x8fPDy8uLuu+9m/fr1NvtLSkrirbfeolq1ari5uVGiRAnuvPNOlixZYh0TFRVFnz59KF++PK6urvj7+/Pggw/yzz//ZPg9Hn/8ceBap+x6W7ZsYf/+/dYxCxcupFOnTpQtWxZXV1eqVKnC22+/TUpKyi2PV3r3oK1evZrGjRvj5uZGlSpVmD59errbfv3119x1112UKlUKV1dXatWqdcNlghUrVmT37t2EhYVZLz1Lu88no3t5fvzxR4KDg3F3d6dkyZI88cQTRERE2Izp3bs3Xl5eRERE0LlzZ7y8vPDz8+OVV17J1PdOM3v2bB5++GHuu+8+fH190z3eABs2bKBjx44UK1YMT09P6tWrx6RJk2zG7Nu3j27duuHn54e7uzs1atTg9ddft8mcXvGX3v19NzsvP/zwQ5o3b06JEiVwd3cnODiYn376Kd3cs2bNokmTJnh4eFCsWDFatWrFX3/9BUCvXr0oWbIkSUlJN2zXvn17atSokfGBw3J5YZ06ddiyZQvNmzfH3d2dSpUq8dlnn90wNiEhgVGjRlG1alVcXV0JCAhg2LBhJCQkZPp7Z1dycjJvv/02VapUwdXVlYoVK/Laa6/d8NnpOXnyJJ07d8bT05NSpUrx8ssvZ2o7ESnY1EETEcmC3377jcqVK9O8efNMb7Ns2TLmzZtH//79KVmypLWoaNmyJT4+PgwbNgxnZ2emT59OmzZtCAsLo2nTpoDll+uxY8fSt29fmjRpQmxsLJs3b2br1q3cc889AHTt2pXdu3czYMAAKlasyOnTp1myZAnHjx/PsFtTqVIlmjdvzrx58/j4449xcnKyvpdWRDz22GMAfPPNN3h5eTF48GC8vLxYtmwZb775JrGxsXzwwQdZOn47d+6kffv2+Pn5MXr0aJKTkxk1ahSlS5e+Yey0adOoXbs2DzzwAEWKFOG3337jxRdfJDU1lX79+gEwceJEBgwYgJeXl7VYSW9fab755hv69OlD48aNGTt2LNHR0UyaNIk1a9awbds2ihYtah2bkpJCaGgoTZs25cMPP+Tvv//mo48+okqVKpm6VHHDhg0cOnSIr7/+GhcXFx566CG+//57XnvtNZtxS5Ys4b777sPf35+BAwdSpkwZ9u7dy++//24t9nfs2EHLli1xdnbm2WefpWLFihw+fJjffvuNd99995ZZ0pPeeQkwadIkHnjgAR5//HESExOZM2cOjzzyCL///judOnWybv/WW28xevRomjdvzpgxY3BxcWHDhg0sW7aM9u3b8+STT/Ldd9+xePFi7rvvPut2UVFRLFu2jFGjRt0y4/nz5+nYsSPdunWjR48ezJs3jxdeeAEXFxeeeuopwNIFe+CBB1i9ejXPPvssNWvWZOfOnXz88cccOHCABQsWZOp7ZyQlJYWzZ8/arHNzc8PLywuAvn378u233/Lwww8zZMgQNmzYwNixY9m7dy/z58/PcL/x8fHcfffdHD9+nJdeeomyZcsyc+ZMli1bdsvjIiIFnCEiIpkSExNjAMaDDz6Y6W0Aw9HR0di9e7fN+s6dOxsuLi7G4cOHretOnTpleHt7G61atbKuq1+/vtGpU6cM93/+/HkDMD744IPMf5Grpk6dagDG4sWLretSUlKMcuXKGSEhIdZ1ly9fvmHb5557zvDw8DCuXLliXderVy8jMDDQZhxgjBo1yvrnzp07G25ubsaxY8es6/bs2WM4OTkZ//2/pPQ+NzQ01KhcubLNutq1axutW7e+Yezy5csNwFi+fLlhGIaRmJholCpVyqhTp44RHx9vHff7778bgPHmm2/afBfAGDNmjM0+77jjDiM4OPiGz0pP//79jYCAACM1NdUwDMP466+/DMDYtm2bdUxycrJRqVIlIzAw0Dh//rzN9mnbGYZhtGrVyvD29rY5bv8dk97xNwzDGDVq1A3HNqPz0jBuPO6JiYlGnTp1jLvuusu67uDBg4ajo6PRpUsXIyUlJd1MKSkpRvny5Y3u3bvbvD9hwgTDwcHBOHLkyA2ffb3WrVsbgPHRRx9Z1yUkJBgNGjQwSpUqZSQmJhqGYRgzZ840HB0djVWrVtls/9lnnxmAsWbNmkx975tl+O+rV69ehmEYRnh4uAEYffv2tdnulVdeMQBj2bJlNvu6/jydOHGiARjz5s2zrouLizOqVq1qc96KSOGjSxxFRDIpNjYWAG9v7yxt17p1a2rVqmX9c0pKCn/99RedO3emcuXK1vX+/v489thjrF692vpZRYsWZffu3Rw8eDDdfbu7u+Pi4sKKFSs4f/58lnJ1794dZ2dnm8vuwsLCiIiIsF7emPYZaS5evMjZs2dp2bIlly9fztJMdikpKSxevJjOnTtToUIF6/qaNWsSGhqa7ndLExMTw9mzZ2ndujVHjhwhJiYm05+bZvPmzZw+fZoXX3zR5p6jTp06ERQUlO69g88//7zNn1u2bMmRI0du+VnJycnMnTuX7t27Wy8vTLtc8/vvv7eO27ZtG0ePHmXQoEE23TvAut2ZM2dYuXIlTz31lM1xu35Mdvz3vExz/XE/f/48MTExtGzZkq1bt1rXL1iwgNTUVN58800cHW1/lUjL5OjoyOOPP86vv/7KxYsXre9///33NG/enEqVKt0yY5EiRXjuueesf3ZxceG5557j9OnTbNmyBbBcslqzZk2CgoI4e/as9XXXXXcBsHz58kx974xUrFiRJUuW2LyGDRsGwJ9//glww2ynQ4YMAbjp/ah//vkn/v7+PPzww9Z1Hh4ePPvss5nOJiIFkwo0EZFM8vHxAbD5ZTMz/vuL6JkzZ7h8+XK69+DUrFmT1NRUTpw4AcCYMWO4cOEC1atXp27dugwdOpQdO3ZYx7u6ujJu3Dj+97//Ubp0aVq1asX48eOJioqyjomJiSEqKsr6OnfuHAAlSpQgNDSU+fPnc+XKFcByeWORIkXo1q2bdfvdu3fTpUsXfH198fHxwc/PzzppQlYKpTNnzhAfH0+1atVueC+9Y7FmzRratWuHp6cnRYsWxc/Pz3p5YHYKtGPHjmX4WUFBQdb307i5ueHn52ezrlixYpkqhP/66y/OnDlDkyZNOHToEIcOHeLo0aO0bduWH374gdTUVMDyuAaAOnXqZLivtILwZmOyI6MC6ffff6dZs2a4ublRvHhx/Pz8mDZtms0xP3z4MI6OjrcsdHr27El8fLz1Ur/9+/ezZcsWnnzyyUxlLFu2LJ6enjbrqlevDmC9x/LgwYPs3r0bPz8/m1fauNOnT2fqe2fE09OTdu3a2bzSvvexY8dwdHSkatWqNtuUKVOGokWL3nBOXe/YsWNUrVr1hiL7VvfmiUjBpwJNRCSTfHx8KFu2LLt27crSdtd3JLKqVatWHD58mBkzZlCnTh2+/PJLGjZsyJdffmkdM2jQIA4cOMDYsWNxc3PjjTfeoGbNmmzbtg2AgQMH4u/vb3099NBD1m2feOIJYmNj+f3330lMTOTnn3+23iMGcOHCBVq3bs327dsZM2YMv/32G0uWLGHcuHEA1kIjpx0+fJi7776bs2fPMmHCBP744w+WLFnCyy+/nKufe73r78vLqrQuWbdu3ahWrZr1NXfuXCIiIggLC8upmFYZddMymtQkvfNy1apVPPDAA7i5ufHpp5/y559/smTJEh577DEMw8hyplq1ahEcHMysWbMAy6QiLi4uNv8AcLtSU1OpW7fuDV2utNeLL75oM/52/nvMSE4/ZF1ECjdNEiIikgX33Xcfn3/+OevWrSMkJCRb+/Dz88PDw4P9+/ff8N6+fftwdHQkICDAuq548eL06dOHPn36cOnSJVq1asXo0aPp27evdUyVKlUYMmQIQ4YM4eDBgzRo0ICPPvqIWbNmMWzYMJtpwosVK2ZdfuCBB/D29mb27Nk4Oztz/vx5m8sbV6xYwb///ssvv/xCq1atrOuPHj2are/t7u6e7uWa/z0Wv/32GwkJCfz66682l/X993I1yPwvx4GBgdbPSrv87frPT3v/dsXFxbFw4UK6d+9uc/lampdeeonvv/+etm3bUqVKFQB27dpFu3bt0t1f2mWwt/qHgWLFinHhwoUb1t+si/NfP//8M25ubixevBhXV1fr+q+//tpmXJUqVUhNTWXPnj00aNDgpvvs2bMngwcPJjIyktmzZ9OpUyebc/BmTp06RVxcnE0X7cCBAwDWyT2qVKnC9u3bufvuu/O8UAoMDCQ1NZWDBw9Ss2ZN6/ro6GguXLhw03MqMDCQXbt2YRiGTe70/l4QkcJFHTQRkSwYNmwYnp6e9O3bl+jo6BveP3z48A3To/+Xk5MT7du3Z+HChTZT4UdHRzN79mzuvPNO6+WU//77r822Xl5eVK1a1ToV9+XLl62XJ6apUqUK3t7e1jG1atWyuTwrODjYOtbd3Z0uXbrw559/Mm3aNDw9PXnwwQdtsgI23ZPExEQ+/fTTm37HjL53aGgoCxYs4Pjx49b1e/fuZfHixTeM/e/nxsTE3FAogOUStPQKk/9q1KgRpUqV4rPPPrOZyvx///sfe/futZmh8HbMnz+fuLg4+vXrx8MPP3zD67777uPnn38mISGBhg0bUqlSJSZOnHjDd0j77n5+frRq1YoZM2bYHLfrx4Dlf/eYmBibS2AjIyNvOpPgfzk5OeHg4GDTdfvnn39umAmxc+fOODo6MmbMmBu6mf/ttPXo0QMHBwcGDhzIkSNHsvRMseTkZJvHMCQmJjJ9+nT8/Pys53G3bt2IiIjgiy++uGH7+Ph44uLiMv15WdWxY0fAMpvo9SZMmABw03OqY8eOnDp1yuYRBpcvX7brh9yLSN5QB01EJAuqVKnC7Nmz6d69OzVr1qRnz57UqVOHxMRE1q5dy48//kjv3r1vuZ933nmHJUuWcOedd/Liiy9SpEgRpk+fTkJCAuPHj7eOq1WrFm3atCE4OJjixYuzefNmfvrpJ/r37w9Yugl333033bp1o1atWhQpUoT58+cTHR3No48+mqnv9MQTT1inQ3/88cdtuhXNmzenWLFi9OrVi5deegkHBwdmzpyZrcvdwDI1+6JFi2jZsiUvvvgiycnJTJ48mdq1a9sUFu3bt8fFxYX777+f5557jkuXLvHFF19QqlQpIiMjbfYZHBzMtGnTeOedd6hatSqlSpW6oUMG4OzszLhx4+jTpw+tW7emR48e1mn2K1asaL188nZ9//33lChRIsNHMTzwwAN88cUX/PHHHzz00ENMmzaN+++/nwYNGtCnTx/8/f3Zt28fu3fvthaun3zyCXfeeScNGzbk2WefpVKlSvzzzz/88ccfhIeHA/Doo4/y6quv0qVLF1566SUuX77MtGnTqF69us0EHzfTqVMnJkyYwL333stjjz3G6dOnmTp1KlWrVrX536dq1aq8/vrrvP3227Rs2ZKHHnoIV1dXNm3aRNmyZRk7dqx1rJ+fH/feey8//vgjRYsWzVIhXLZsWcaNG8c///xD9erVmTt3LuHh4Xz++ec4OzsD8OSTTzJv3jyef/55li9fTosWLUhJSWHfvn3MmzePxYsX06hRo0x/ZlbUr1+fXr168fnnn1svB964cSPffvstnTt3pm3bthlu+8wzzzBlyhR69uzJli1b8Pf3Z+bMmXh4eORKVhHJR8ybQFJEJP86cOCA8cwzzxgVK1Y0XFxcDG9vb6NFixbG5MmTbaaeB4x+/fqlu4+tW7caoaGhhpeXl+Hh4WG0bdvWWLt2rc2Yd955x2jSpIlRtGhRw93d3QgKCjLeffdd6xTjZ8+eNfr162cEBQUZnp6ehq+vr9G0aVObqbtvJTk52fD39zcA488//7zh/TVr1hjNmjUz3N3djbJlyxrDhg0zFi9efMNU4JmZZt8wDCMsLMwIDg42XFxcjMqVKxufffZZulPB//rrr0a9evUMNzc3o2LFisa4ceOMGTNmGIBx9OhR67ioqCijU6dOhre3twFYpzL/7zT7aebOnWvccccdhqurq1G8eHHj8ccfN06ePGkzplevXoanp+cNxyK9nNeLjo42ihQpYjz55JMZjrl8+bLh4eFhdOnSxbpu9erVxj333GN4e3sbnp6eRr169YzJkyfbbLdr1y6jS5cuRtGiRQ03NzejRo0axhtvvGEz5q+//jLq1KljuLi4GDVq1DBmzZqV4TT7GZ2XX331lVGtWjXD1dXVCAoKMr7++usMv/eMGTOsx7JYsWJG69atjSVLltwwbt68eQZgPPvssxkel/9q3bq1Ubt2bWPz5s1GSEiI4ebmZgQGBhpTpky5YWxiYqIxbtw4o3bt2tYswcHBxltvvWXExMRk6nvfLMPNJCUlGW+99ZZRqVIlw9nZ2QgICDBGjBhh8/dA2r7++ziIY8eOGQ888IDh4eFhlCxZ0hg4cKCxaNEiTbMvUsg5GEY2/xlUREREJBMWLlxI586dWblyJS1btszUNm3atOHs2bNZnpRHRCS/0z1oIiIikqu++OILKleuzJ133ml2FBERu6d70ERERCRXzJkzhx07dvDHH38wadIkTUcvIpIJKtBEREQkV/To0QMvLy+efvrpG55HJiIi6dM9aCIiIiIiInZC96CJiIiIiIjYCRVoIiIiIiIidkL3oOWi1NRUTp06hbe3t26MFhEREREpxAzD4OLFi5QtWxZHx4z7ZCrQctGpU6cICAgwO4aIiIiIiNiJEydOUL58+QzfV4GWi7y9vQHL/wg+Pj4mpxEREREREbPExsYSEBBgrREyogItF6Vd1ujj46MCTUREREREbnnrkyYJERERERERsRMq0EREREREROyECjQRERERERE7oQJNRERERETETqhAExERERERsRMq0EREREREROyECjQRERERERE7oQJNRERERETETqhAExERERERsRNFzA4guejCCbj8LymGwe6IWM5dTqS4hwu1y/ng5OAAHiWgaIDZKUXSp/NX8jOdv1IApKQabDx6jtMXr1DK240mlYrj5OhgdiyRW8vnfwebWqCtXLmSDz74gC1bthAZGcn8+fPp3LnzTbdZsWIFgwcPZvfu3QQEBDBy5Eh69+5tM2bq1Kl88MEHREVFUb9+fSZPnkyTJk2s71+5coUhQ4YwZ84cEhISCA0N5dNPP6V06dLWMcePH+eFF15g+fLleHl50atXL8aOHUuRIvmkpr1wAqYEQ3ICTkC99MYUcYX+W+z6BJVCSuev5Gc6f6UAWLQrkrd+20NkzBXrOn9fN0bdX4t76/ibmEzkFgrA38GmXuIYFxdH/fr1mTp1aqbGHz16lE6dOtG2bVvCw8MZNGgQffv2ZfHixdYxc+fOZfDgwYwaNYqtW7dSv359QkNDOX36tHXMyy+/zG+//caPP/5IWFgYp06d4qGHHrK+n5KSQqdOnUhMTGTt2rV8++23fPPNN7z55ps59+Vz2+V/ITnh5mOSEyzjROyNzl/Jz3T+Sj63aFckL8zaalOcAUTFXOGFWVtZtCvSpGQimVAA/g42tR3UoUMHOnTokOnxn332GZUqVeKjjz4CoGbNmqxevZqPP/6Y0NBQACZMmMAzzzxDnz59rNv88ccfzJgxg+HDhxMTE8NXX33F7NmzueuuuwD4+uuvqVmzJuvXr6dZs2b89ddf7Nmzh7///pvSpUvToEED3n77bV599VVGjx6Ni4tLDh+JnJdiGDhlYlxcYjIOicm5nkckK4zEZDwzMU7nr9gjnb+Sn6WkGoz6dTdGOu8ZgAMw+tc9tKhaUpc7il3K7N/Bmf1d2Qz55Ho9i3Xr1tGuXTubdaGhoQwaNAiAxMREtmzZwogRI6zvOzo60q5dO9atWwfAli1bSEpKstlPUFAQFSpUYN26dTRr1ox169ZRt25dm0seQ0NDeeGFF9i9ezd33HFHuvkSEhJISLhWscfGxt72d86u3RGx6bd0/+P0jMe4gv0XnFK4uJFIpUz093X+ij3K7Pnbbfp6dhvRuR9IJAcZQFTsFeqO/svsKCLpqu1wlD9cbz1ud0Qs9crlfp7syFcFWlRUlE3RBFC6dGliY2OJj4/n/PnzpKSkpDtm37591n24uLhQtGjRG8ZERUXd9HPS3svI2LFjeeutt7L13XLaucuJmRpXyVG/HEj+pfNXREREsiOzvyubIV8VaPZuxIgRDB482Prn2NhYAgLMufmwuEfmugoHGo2mQrW6uZxGJGuOH9xJ9c2jbzlO56/Yo8yev289UJtawS1zP5BIFmw8eo7eX2+65bhv+jSmSaXieZBIJGv2bFkFi289LrO/K5shXxVoZcqUITra9l/Mo6Oj8fHxwd3dHScnJ5ycnNIdU6ZMGes+EhMTuXDhgk0X7b9jNm7ceMM+0t7LiKurK66umeip5oHa5XwyNa7KHW1wKpf+JZsiZqniVQI2Z2LcHTp/xf5k9vy9o0JRnFzy1f8NSyHQspof/r5uRMVcSfc+NAegjK8bLav56R40sUt3VCiaqXGZ/V3ZDPnqQdUhISEsXbrUZt2SJUsICQkBwMXFheDgYJsxqampLF261DomODgYZ2dnmzH79+/n+PHj1jEhISHs3LnTZubHJUuW4OPjQ61atXLt++UkJ4fM/aWZ2XEieUnnr+RnOn8lP3NydGDU/Zbfdf57hqb9edT9tVScid0qCH8Hm1qgXbp0ifDwcMLDwwHLNPrh4eEcP34csFwy2LNnT+v4559/niNHjjBs2DD27dvHp59+yrx583j55ZetYwYPHswXX3zBt99+y969e3nhhReIi4uzzuro6+vL008/zeDBg1m+fDlbtmyhT58+hISE0KxZMwDat29PrVq1ePLJJ9m+fTuLFy9m5MiR9OvXz246ZLfkUcLyjIebKeJqGSdib3T+Sn6m81fyuXvr+DPtiYaU8XWzWV/G141pTzTUc9DEvnkU58Z/XvgPO/872MEwjPQ62HlixYoVtG3b9ob1vXr14ptvvqF37978888/rFixwmabl19+mT179lC+fHneeOONGx5UPWXKFOuDqhs0aMAnn3xC06ZNre+nPaj6hx9+sHlQ9fWXLx47dowXXniBFStW4OnpSa9evXj//fez9KDq2NhYfH19iYmJwcfHhDZqPn+KuhRyOn8lP0vn/C1/5SBV148AhyLQ50+o0PTW+xExUUqqwcaj5zh98QqlvN1oUqm4Omdi/w4thVkPgZMLKd1/YPcFZ7v5HSKztYGpBVpBZ3qBJiIi9uXbB+BoGDTsBQ98YnYaEZGCxTDgq3vg5CZo9iLcO9bsRDYyWxvkq3vQRERE8rW2r1l+hn8P5/8xNYqISIFzaKmlOCviDi0GmZ0m21SgiYiI5JUKzaByW0hNhpUfmp1GRKTgMAxYcbVj1vhp8C598/F2TAWaiIhIXrJ20WbDuaPmZhERKSgO/Q0Rm692zwaanea2qEATERHJSwFNoMrdYKTAKnXRRERum2HA8vcsy036glcpc/PcJhVoIiIiea3NCMvP8B/g3BFzs4iI5HcH/4JTW8HZA5rn7+4ZqEATERHJewGNoWo7SxdN96KJiGSfzb1nfcHLz9w8OUAFmoiIiBnaXL0Xbfsc+PewuVlERPKrA4vg1DZw9sz3956lUYEmIiJihvLBUK391S7aB2anERHJf67vnjV5BjxLmpsnh6hAExERMUub4ZafO+bC2UPmZhERyW/2/w8it4OLFzR/yew0OUYFmoiIiFnKBUP1e8FIVRdNRCQrbLpnz4JnCXPz5CAVaCIiImZK66LtnAdnD5qbRUQkv9j3B0TtuNo9G2B2mhylAk1ERMRMZe+A6h0sXbSw8WanERGxf6mpsOJ9y3LT58CjuLl5cpgKNBEREbOlddF2/QRnDpibRUTE3u37HaJ3gos3hPQ3O02OU4EmIiJitrINoEanq120cWanERGxX6nX/T3Z7PkC1z0DFWgiIiL2wdpF+xnO7Dc3i4iIvdr3G0TvAlcfCOlndppcoQJNRETEHvjXg6D7AENdNBGR9Fx/71mzF8C9mLl5cokKNBEREXth7aL9Aqf3mptFRMTe7F0Ip/eAq6+lQCugVKCJiIjYizJ1oeb9qIsmIvIfqamwIu3es4LbPQMVaCIiIval9dUu2u4FEL3H1CgiInZjz3w4s7fAd89ABZqIiIh9KVMHaj2IpYv2vtlpRETMl5py7TmRIf3AvaipcXKbCjQRERF703o44AB7FkL0brPTiIiYa/d8OLMP3HwtU+sXcCrQRERE7E3pWlC7s2V5hbpoIlKIpaZcuyc3pL+lSCvgVKCJiIjYo9avAg6w91eI2ml2GhERc+z6Bc4eALei0LTgd89ABZqIiIh9KlUTanexLKuLJiKF0fXds+b9wc3H3Dx5RAWaiIiIvUrrou37HSJ3mJ1GRCRv7fwJ/j1omVK/yXNmp8kzKtBERETsVakgqNPVsqwumogUJinJsPLqzI3NBxSa7hmoQBMREbFvrV8FB0fY/wdEbjc7jYhI3tj1E/x7CNyLQ5NnzU6Tp1SgiYiI2DO/6lDnYcuyumgiUhikJF9379kAcPU2N08eU4EmIiJi71oPu9pF+xNObTM7jYhI7to5D84dAY8Sha57BirQRERE7F/JalD3EcuyumgiUpClJENY2r1nL4Grl7l5TKACTUREJD9odbWLdmARRGwxO42ISO7YMQfOHwWPktDkGbPTmEIFmoiISH5QsirU625ZVhdNRAqilCRY+YFlucVAcPE0N49JVKCJiIjkF62GgoMTHPwLTqqLJiIFzPY5cP4f8PSDxk+bncY0KtBERETyixJVoP6jluUVY83NIiKSk9Q9s1KBJiIikp+0esXSRTu0BE5sMjuNiEjOCJ8NF46BZyloVHi7Z6ACTUREJH8pXhnq97Asq4smIgVBciKs/NCyfOcgcPEwNY7ZVKCJiIjkN61eAccicHgpnNhodhoRkdsT/j3EHAev0tDoKbPTmE4FmoiISH5TvNK1Ltry98zNIiJyO5ITYdVHluU7XwZnd3Pz2AEVaCIiIvlRq6GWLtqR5XB8vdlpRESyJ3wWxJwArzIQ3NvsNHZBBZqIiEh+VCwQGjxuWda9aCKSHyUnwEp1z/5LBZqIiEh+lXYv2pEVcGyd2WlERLJm20yIPQne/uqeXUcFmoiISH5VtALc8YRleYXuRRORfCQ5AVZNsCzfORic3czNY0dUoImIiORnLV8BR2c4uhL+WWN2GhGRzNn6HcRGgHdZaNjT7DR2RQWaiIhIflY0ABo+aVnWvWgikh8kXbnWPWup7tl/qUATERHJ71oOAScX+GcVHF1ldhoRkZvb+h1cPAU+5dQ9S4cKNBERkfzOt/y1X3JWvG9uFhGRm0m6Aquv654VcTU3jx1SgSYiIlIQ3DnY0kU7ttpyP5qIiD3a8g1cjASf8nDHk2ansUsq0ERERAoC33LQsJdleflYMAxz84iI/FdS/LXuWash6p5lQAWaiIhIQdFyMDi5wvG1cDTM7DQiIrY2fw2XosG3AjR4wuw0dksFmoiISEHhU/baw17VRRMRe5IUD2smWpZbDYEiLqbGsWcq0ERERAqSO1+GIm5wYj0cWWF2GhERi80zLN2zohWg/mNmp7FrKtBEREQKEh9/CO5jWV6hLpqI2IHEy7B6omW55Svqnt2CCjQREZGC5s5BV7toG+DwMrPTiEhht/kriDsNRQOhgbpnt6ICTUREpKDxLgONnrIsq4smImZKjLvWPWs1FJycTY2TH6hAExERKYhaDIIi7nByExxaanYaESmsNn0Jl89CsYpQ/1Gz0+QLKtBEREQKIu/S0Phpy/KK99RFE5G8lxgHayZZllsNU/csk1SgiYiIFFQtBlq6aBFb4NDfZqcRkcJm4xdw+V8oVgnqdTc7Tb6hAk1ERKSg8ioFTfpalperiyYieSjhEqz9xLLcehg4FTE3Tz6iAk1ERKQgaz4QnD3g1FY4+JfZaUSksNj4uaV7VrwK1O1mdpp8RQWaiIhIQeblB42vdtE0o6OI5IWEi+qe3QbTC7SpU6dSsWJF3NzcaNq0KRs3bsxwbFJSEmPGjKFKlSq4ublRv359Fi1aZDPm4sWLDBo0iMDAQNzd3WnevDmbNm2yGRMdHU3v3r0pW7YsHh4e3HvvvRw8eNBmTJs2bXBwcLB5Pf/88zn3xUVERPJKi4Hg7AmntsGBRbceLyJyOzZMh/jzUKIq1HnY7DT5jqkF2ty5cxk8eDCjRo1i69at1K9fn9DQUE6fPp3u+JEjRzJ9+nQmT57Mnj17eP755+nSpQvbtm2zjunbty9Llixh5syZ7Ny5k/bt29OuXTsiIiIAMAyDzp07c+TIERYuXMi2bdsIDAykXbt2xMXF2XzeM888Q2RkpPU1fvz43DsYIiIiucWzJDR5xrKsLpqI5KYrsbBuimW59avqnmWDg2GY97d006ZNady4MVOmWP5HTE1NJSAggAEDBjB8+PAbxpctW5bXX3+dfv36Wdd17doVd3d3Zs2aRXx8PN7e3ixcuJBOnTpZxwQHB9OhQwfeeecdDhw4QI0aNdi1axe1a9e2fm6ZMmV477336NvXchlImzZtaNCgARMnTsz294uNjcXX15eYmBh8fHyyvR8REZHbFvcvTKoHiZfg0R8gqKPZiUSkIFr5ASx7B0pUg34bwNHJ7ER2I7O1gWkdtMTERLZs2UK7du2uhXF0pF27dqxbty7dbRISEnBzc7NZ5+7uzurVqwFITk4mJSXlpmMSEhIAbMY4Ojri6upqHZPm+++/p2TJktSpU4cRI0Zw+fLlm36nhIQEYmNjbV4iIiJ2wbMENHnWsqwumojkhisxsPa67pmKs2wxrUA7e/YsKSkplC5d2mZ96dKliYqKSneb0NBQJkyYwMGDB0lNTWXJkiX88ssvREZGAuDt7U1ISAhvv/02p06dIiUlhVmzZrFu3TrrmKCgICpUqMCIESM4f/48iYmJjBs3jpMnT1rHADz22GPMmjWL5cuXM2LECGbOnMkTTzxx0+80duxYfH19ra+AgIDbOUQiIiI5q/kAcPGCqB2w7w+z04hIQbNhOly5ACVrQJ2HzE6Tb5k+SUhWTJo0iWrVqhEUFISLiwv9+/enT58+ODpe+xozZ87EMAzKlSuHq6srn3zyCT169LCOcXZ25pdffuHAgQMUL14cDw8Pli9fTocOHWz28+yzzxIaGkrdunV5/PHH+e6775g/fz6HDx/OMN+IESOIiYmxvk6cOJF7B0NERCSrPIpD0+csyyveh9RUc/OISMERf+G6e8+GqXt2G0wr0EqWLImTkxPR0dE266OjoylTpky62/j5+bFgwQLi4uI4duwY+/btw8vLi8qVK1vHVKlShbCwMC5dusSJEyfYuHEjSUlJNmOCg4MJDw/nwoULREZGsmjRIv7991+bMf/VtGlTAA4dOpThGFdXV3x8fGxeIiIidiWkP7h4Q/RO2Pe72WlEpKDY8JnlEke/IKjdxew0+ZppBZqLiwvBwcEsXbrUui41NZWlS5cSEhJy023d3NwoV64cycnJ/Pzzzzz44IM3jPH09MTf35/z58+zePHidMf4+vri5+fHwYMH2bx5c7pj0oSHhwPg7++fyW8oIiJihzyKQ7Orj41RF01EckL8BVj3qWVZ957dNlPnvRw8eDC9evWiUaNGNGnShIkTJxIXF0efPn0A6NmzJ+XKlWPs2LEAbNiwgYiICBo0aEBERASjR48mNTWVYcOGWfe5ePFiDMOgRo0aHDp0iKFDhxIUFGTdJ8CPP/6In58fFSpUYOfOnQwcOJDOnTvTvn17AA4fPszs2bPp2LEjJUqUYMeOHbz88su0atWKevXq5eEREhERyQUh/Sz3ipzeDft+g1oZ/wOliMgtrZ8GCTHgVxNqdTY7Tb5naoHWvXt3zpw5w5tvvklUVBQNGjRg0aJF1olDjh8/bnNf2JUrVxg5ciRHjhzBy8uLjh07MnPmTIoWLWodExMTw4gRIzh58iTFixena9euvPvuuzg7O1vHREZGMnjwYKKjo/H396dnz5688cYb1vddXFz4+++/rQVjQEAAXbt2ZeTIkbl/UERERHKbezFo9gKEjbN00YLuB8d8dVu6iNiL+POw/mr3rM2r+rskB5j6HLSCTs9BExERuxV/HibWt/yr9yPf6J4REcmeZe/CyvFQqjY8v1oF2k3Y/XPQRERExERpXTSAFeN0L5qIZN3lc5bLG0HdsxykoygiIlJYNXsBXH3hzF7YM9/sNCKS36ybCokXoXQdy6XSkiNUoImIiBRW7kUtE4bA1S5aiqlxRCQfuXzOMtkQQJvh6p7lIB1JERGRwqzZ8+DmC2f3w2510UQkk9ZNsXTPytSFoPvMTlOgqEATEREpzNx8IWSAZTlMXTQRyYS4f691z1oPBwcHc/MUMCrQRERECrumz4FbUTh7AHb9YnYaEbF36yZD4iUoUw+COpmdpsBRgSYiIlLYuflA8/6WZXXRRORm4s7Chs8ty21GqHuWC1SgiYiICDR5zjL1/r8HYedPZqcREXu19hNIigP/BlCjg9lpCiQVaCIiInK1i3bdvWgpyebmERH7E3cWNn5hWVb3LNeoQBMRERGLJs+Ce3E4dxh2qYsmIv+xZhIkXYayd0D1ULPTFFgq0ERERMTC1RtavGRZVhdNRK536Qxs+tKyrO5ZrlKBJiIiItc0fgY8SsC5I7BzntlpRMRerJlo6Z6VC4Zq7c1OU6CpQBMREZFrXL2geVoXbby6aCICF6Nh01eWZXXPcp0KNBEREbHV5BnwKAnnj8KOOWanERGzrZkEyfFQrhFUbWd2mgJPBZqIiIjYcvGEFgMty2HjISXJ3DwiYp6L0bD5avesrbpneUEFmoiIiNyo8dPg6QcXjsF2ddFECq01EyH5CpRvAlXuNjtNoaACTURERG7k4gktBlmWV36gLppIYXQxCjbPsCy3Ga7uWR5RgSYiIiLpa/QUeJaydNHCZ5udRkTy2uqPLd2zgKZQ5S6z0xQaKtBEREQkfS4ecOcgy/LKDyE50dQ4IpKHYk/B5q8ty5q5MU+pQBMREZGMNXoKvEpDzHEI/97sNCKSV1Z/DCkJUCEEKrcxO02hogJNREREMubsDne+bFle9ZG6aCKFQewp2PKNZVndszynAk1ERERuLrg3eJWBmBMQPsvsNCKS21ZNgJRECGwBlVqZnabQUYEmIiIiN+fsDi0HW5ZXfgTJCebmEZHcE3MStn5rWdbMjaZQgSYiIiK31rAXePtD7EnYNtPsNCKSW6zdszvVPTOJCjQRERG5NWc3uPNqF23VBHXRRAqiCydg63eW5bYjzM1SiKlAExERkcxp2BO8y0JsxLVf4kSk4Fj1EaQmQcWWUPFOs9MUWirQREREJHOc3a7di7bqI0i6Ym4eEck5F47DtquTALV9zdwshZwKNBEREcm8hj3BpzxcjFQXTaQgSeueVWoNgc3NTlOoqUATERGRzCvieq2LtnqCumgiBcH5Y9e6Z21075nZVKCJiIhI1tzxxLUuWtrDbEUk/1r1IaQmQ+U2EBhidppCTwWaiIiIZE0RV2g1xLK8egIkxZubR0Sy7/w/ED7bstxG957ZAxVoIiIiknUNngDfCnApGjZ/bXYaEcmulR9YumdV7oIKTc1OI6hAExERkewo4nJdF+1jSLxsbh4RybpzRyH8B8uyumd2QwWaiIiIZE+Dx6FoBYg7DVvURRPJd1Z+CEYKVG0HAY3NTiNXqUATERGR7HFyhlZDLcurJ6qLJpKf/HsYtqd1zzRzoz1RgSYiIiLZV78HFA20dNE2f2V2GhHJLGv37B4o38jsNHIdFWgiIiKSfTd00eJMjSMimfDvYdgxx7Ks7pndUYEmIiIit6f+o1CsIlw+C5u+NDuNiNxK2HgwUqFaKJQPNjuN/IcKNBEREbk9Ts7Qaphlec0kddFE7NnZQ7BznmW5zXBzs0i6VKCJiIjI7avXHYpXhsv/wsYvzE4jIhlZebV7Vr0DlGtodhpJhwo0ERERuX1ORa510dZ+AgmXzM0jIjc6exB2/mhZbvOquVkkQyrQREREJGfUfQSKV7naRfvc7DQi8l9h4yzdsxodoewdZqeRDKhAExERkZzhVARaX99Fu2huHhG55sx+2PmTZVn3ntk1FWgiIiKSc+o8DCWqQvx52DDd7DQikiZsHGBA0H3gX9/sNHITKtBEREQk5zgVgdZX721ZNwWuxJqbR0Tg9D7Y9YtlWd0zu6cCTURERHJWna5Qsrqli7ZRXTQR06V1z2reD2Xqmp1GbkEFmoiIiOQsR6drXbS1U+BKjLl5RAqz03th93zLcmt1z/IDFWgiIiKS82p3gZI14MoF3YsmYqYV72Ppnj0AZeqYnUYyQQWaiIiI5DxHp2szOq6bAvEXTI0jUihF74Y9CyzLuvcs31CBJiIiIrmjdhfwC7Jc4rjhM7PTiBQ+YeMsP2t1htK1TY0imacCTURERHLH9feirftUXTSRvBS1C/YsBBzUPctnVKCJiIhI7qnVGUrVgoQYWD/N7DQihUfY+5aftbtAqZrmZpEsUYEmIiIiucfR8VoXbf2nlqn3RSR3Re6Avb8BDtf++5N8QwWaiIiI5K6aD0Cp2pAQa7nUUURyV9q9Z3UeglJB5maRLFOBJiIiIrnL0RHapHXRpsHlc+bmESnIIrfDvt9R9yz/UoEmIiIiuS/ofihdBxIvwrqpZqcRKbhWXO2e1X0Y/GqYm0WyRQWaiIiI5D5Hx2szyW2Yri6aSG44FQ77/wAHR3XP8jEVaCIiIpI3gu6DMnWvdtGmmJ1GpOBZcXXmxrqPQMlq5maRbFOBJiIiInnDwQHajLAsb5gOcf+am0ekIInYCgf+Z+metRpmdhq5DaYXaFOnTqVixYq4ubnRtGlTNm7cmOHYpKQkxowZQ5UqVXBzc6N+/fosWrTIZszFixcZNGgQgYGBuLu707x5czZt2mQzJjo6mt69e1O2bFk8PDy49957OXjwoM2YK1eu0K9fP0qUKIGXlxddu3YlOjo65764iIhIYVSjI5SpB4mXYN1ks9OIFBzW7lk3KFnV3CxyW0wt0ObOncvgwYMZNWoUW7dupX79+oSGhnL69Ol0x48cOZLp06czefJk9uzZw/PPP0+XLl3Ytm2bdUzfvn1ZsmQJM2fOZOfOnbRv35527doREREBgGEYdO7cmSNHjrBw4UK2bdtGYGAg7dq1Iy4uzrqfl19+md9++40ff/yRsLAwTp06xUMPPZS7B0RERKSgs+mifQ5xZ83NI1IQnNwCBxeDgxO0Vvcsv3MwDMMw68ObNm1K48aNmTLFch16amoqAQEBDBgwgOHDh98wvmzZsrz++uv069fPuq5r1664u7sza9Ys4uPj8fb2ZuHChXTq1Mk6Jjg4mA4dOvDOO+9w4MABatSowa5du6hdu7b1c8uUKcN7771H3759iYmJwc/Pj9mzZ/Pwww8DsG/fPmrWrMm6deto1qxZpr5fbGwsvr6+xMTE4OPjk+3jJCIiUqAYBnzeBiLDocVAuGeM2YlE8rfvH4GDf0H9x6DLNLPTSAYyWxuY1kFLTExky5YttGvX7loYR0fatWvHunXr0t0mISEBNzc3m3Xu7u6sXr0agOTkZFJSUm46JiEhAcBmjKOjI66urtYxW7ZsISkpySZbUFAQFSpUyDBb2r5jY2NtXiIiIvIf13fRNn6hLprI7Ti52VKcOThB66Fmp5EcYFqBdvbsWVJSUihdurTN+tKlSxMVFZXuNqGhoUyYMIGDBw+SmprKkiVL+OWXX4iMjATA29ubkJAQ3n77bU6dOkVKSgqzZs1i3bp11jFphdaIESM4f/48iYmJjBs3jpMnT1rHREVF4eLiQtGiRTOdDWDs2LH4+vpaXwEBAdk9PCIiIgVb9VAo2xCSLsOaSWanEcm/Voy1/KzfA4pXNjeL5AjTJwnJikmTJlGtWjWCgoJwcXGhf//+9OnTB0fHa19j5syZGIZBuXLlcHV15ZNPPqFHjx7WMc7Ozvzyyy8cOHCA4sWL4+HhwfLly+nQoYPNfrJjxIgRxMTEWF8nTpy4rf2JiIgUWNd30TZ9CZfOmJtHJD86sREO/W3pnrUaYnYaySGmFWglS5bEycnphpkRo6OjKVOmTLrb+Pn5sWDBAuLi4jh27Bj79u3Dy8uLypWv/WtBlSpVCAsL49KlS5w4cYKNGzeSlJRkMyY4OJjw8HAuXLhAZGQkixYt4t9//7WOKVOmDImJiVy4cCHT2QBcXV3x8fGxeYmIiEgGqt0D5YKvdtEmmp1GJP9J6541UPesIDGtQHNxcSE4OJilS5da16WmprJ06VJCQkJuuq2bmxvlypUjOTmZn3/+mQcffPCGMZ6envj7+3P+/HkWL16c7hhfX1/8/Pw4ePAgmzdvto4JDg7G2dnZJtv+/fs5fvz4LbOJiIhIJtl00b6Ci3qcjUimHd8Ah5eBYxFopXvPCpIiZn744MGD6dWrF40aNaJJkyZMnDiRuLg4+vTpA0DPnj0pV64cY8da/nVgw4YNRERE0KBBAyIiIhg9ejSpqakMG3ZtOtHFixdjGAY1atTg0KFDDB06lKCgIOs+AX788Uf8/PyoUKECO3fuZODAgXTu3Jn27dsDlsLt6aefZvDgwRQvXhwfHx8GDBhASEhIpmdwFBERkUyo2g7KNYKIzZZ70e59z+xEIvmDtXv2GBSraGoUyVmmFmjdu3fnzJkzvPnmm0RFRdGgQQMWLVpknTjk+PHjNveFXblyhZEjR3LkyBG8vLzo2LEjM2fOtJnMIyYmhhEjRnDy5EmKFy9O165deffdd3F2draOiYyMZPDgwURHR+Pv70/Pnj154403bLJ9/PHHODo60rVrVxISEggNDeXTTz/N3QMiIiJS2Dg4QNsRMKsrbP7KMu2+d+lbbydSmB1fD0eWW7pnLV8xO43ksCw/B61ixYo89dRT9O7dmwoVKuRWrgJBz0ETERHJBMOAr9rDyY3Q7EW4d6zZiUTs27cPwNEwCO4N92sW1Pwi156DNmjQIH755RcqV67MPffcw5w5c6zPFhMRERHJMgcHaDPcsrx5BlzM+JE2IoXesbWW4szRGVpq5saCKFsFWnh4OBs3bqRmzZoMGDAAf39/+vfvz9atW3Mjo4iIiBR0Ve6CgKaQfAVWf2x2GhH7tfzqfZp3PAFFdTVbQZTtWRwbNmzIJ598wqlTpxg1ahRffvkljRs3pkGDBsyYMYMsXjkpIiIihdn1Mzpu/hpiT5mbR8Qe/bMa/lml7lkBl+0CLSkpiXnz5vHAAw8wZMgQGjVqxJdffknXrl157bXXePzxx3Myp4iIiBR0ldtAhRBISVAXTSQ9K963/GzYE4oGmJtFck2WZ3HcunUrX3/9NT/88AOOjo707NmTjz/+mKCgIOuYLl260Lhx4xwNKiIiIgVcWhftuwdgyzdw58vgU9bsVCL24egqS/fMyUXdswIuyx20xo0bc/DgQaZNm0ZERAQffvihTXEGUKlSJR599NEcCykiIiKFRKVWENgCUhJh1QSz04jYB8O49tyzhr3At5y5eSRXZXma/WPHjhEYGJhbeQoUTbMvIiKSDUdXwrf3WzoFL20D3/JmJxIx15EwS2fZyQVeCleBlk/l2jT7p0+fZsOGDTes37BhA5s3b87q7kRERERsVWoFgXeqiyYCtt2z4N4qzgqBLBdo/fr148SJEzesj4iIoF+/fjkSSkRERAq5tldndNz6HVy48fcOkULjyAo4vg6cXOHOwWankTyQ5QJtz549NGzY8Ib1d9xxB3v27MmRUCIiIlLIVbwTKraE1CRY9ZHZaUTMYRjXZm5s1Ad8/M3NI3kiywWaq6sr0dHRN6yPjIykSJEsTwopIiIikr62r1l+bpsFF46bm0XEDEeWw4n1UMTNMqupFApZLtDat2/PiBEjiImJsa67cOECr732Gvfcc0+OhhMREZFCLLA5VGqtLpoUToYBy9PuPesD3mXMzSN5JssF2ocffsiJEycIDAykbdu2tG3blkqVKhEVFcVHH+kvTxEREclBba7ei7ZtFpw/Zm4Wkbx0eCmc3Hi1ezbI7DSSh7JcoJUrV44dO3Ywfvx4atWqRXBwMJMmTWLnzp0EBOiJ5iIiIpKDAkOgchtITYZVH5qdRiRvXN89a/S0umeFTJafgyaZp+egiYiI5IDjG2BGe3AsAgO2QLGKZicSyV0Hl8D3D0MRdxi0A7xKmZ1IckBma4Nsz+qxZ88ejh8/TmJios36Bx54ILu7FBEREblRhaZQ5S44vAxWfgAPTjU7kUjuuf65Z42fVnFWCGW5QDty5AhdunRh586dODg4kNaAc3BwACAlJSVnE4qIiIi0ec1SoIX/AC1fgeKVzE4kkjsOLoGILZbuWYtBZqcRE2T5HrSBAwdSqVIlTp8+jYeHB7t372blypU0atSIFStW5EJEERERKfQCGkPVdmCkwErdiyYFlGHAivcsy036gpefuXnEFFku0NatW8eYMWMoWbIkjo6OODo6cueddzJ27Fheeuml3MgoIiIicm1Gx+0/wL+Hzc0ikhsOLIZT28DZA5oPNDuNmCTLBVpKSgre3t4AlCxZklOnTgEQGBjI/v37czadiIiISJryjaDqPeqiScF0/b1nTZ5R96wQy3KBVqdOHbZv3w5A06ZNGT9+PGvWrGHMmDFUrlw5xwOKiIiIWKV10XbMURdNCpb9/4PIcHD2VPeskMtygTZy5EhSU1MBGDNmDEePHqVly5b8+eeffPLJJzkeUERERMSqfDBUCwUjFcLGm51GJGdc3z1r+ix4ljA3j5gqR56Ddu7cOYoVK2adyVEs9Bw0ERGRXBCxFb5oCw6O0G8TlKxqdiKR27PvD5jzGLh4wcAdKtAKqMzWBlnqoCUlJVGkSBF27dpls7548eIqzkRERCRvlGsI1TtYumgr1UWTfM7m3jN1zySLBZqzszMVKlTQs85ERETEXG1etfzc+SOcPWhuFpHbse93iNoJLt7QfIDZacQOZPketNdff53XXnuNc+fO5UYeERERkVsrewfU6Hj1XrRxZqcRyZ7UVFjxvmW56XPgUdzcPGIXimR1gylTpnDo0CHKli1LYGAgnp6eNu9v3bo1x8KJiIiIZKjNcNj/J+z8CVoNBb8aZicSyZp9v0H0LnD1gZB+ZqcRO5HlAq1z5865EENEREQki/zrQ9B9lkvEwsbBwzPMTiSSeampsOJq97fp8+qeiVWOzOIo6dMsjiIiIrksaid8difgAC+uh1JBZicSyZzdC+DHXpbu2aAd4F7M7ESSy3JlFkcRERERu1KmLtS8HzB0L5rkH6nX3TvZ7AUVZ2IjywWao6MjTk5OGb5ERERE8lTr4Zafu+fD6b3mZhHJjD0L4PQecPWFZi+anUbsTJbvQZs/f77Nn5OSkti2bRvffvstb731Vo4FExEREcmUMnWg5gOw91fLjHjdvjU7kUjGUlOudc9CXgT3oqbGEfuTY/egzZ49m7lz57Jw4cKc2F2BoHvQRERE8kj0bpjW3LL8wlooXdvcPCIZ2fkT/Pw0uPnCoJ2Wn1Io5Pk9aM2aNWPp0qU5tTsRERGRzCtdG2p1tiynPVdKxN6kpkDYeMtySH8VZ5KuHCnQ4uPj+eSTTyhXrlxO7E5EREQk69oMBxwslzpG7TI7jciNds+Hs/vBrajlwdQi6cjyPWjFihXDwcHB+mfDMLh48SIeHh7MmjUrR8OJiIiIZFqpmlC7C+z+BcLeh+76vUTsiM29Z+qeScayXKB9/PHHNgWao6Mjfn5+NG3alGLFNEWoiIiImKj1q5Yuxd7fIHIH+NczO5GIxa6f4ewBy5T66p7JTWS5QOvdu3cuxBARERHJAaWCoM5Dll+Gw8bBo9+bnUgEUpL/0z3T5HGSsSzfg/b111/z448/3rD+xx9/5NtvNa2tiIiImKz1q4AD7PsdIrebnUYEdv0E/x4C9+LqnsktZblAGzt2LCVLlrxhfalSpXjvvfdyJJSIiIhItvnVgLoPW5Y1o6OYLSX52syNzQeAq7e5ecTuZblAO378OJUqVbphfWBgIMePH8+RUCIiIiK3pfWr4OAI+/+EU+Fmp5HCbOePcO6wpXvW5Fmz00g+kOUCrVSpUuzYseOG9du3b6dEiRI5EkpERETktpSsBnUfsSyriyZmSUmGlVe7Zy1eAlcvc/NIvpDlAq1Hjx689NJLLF++nJSUFFJSUli2bBkDBw7k0UcfzY2MIiIiIlnXapili3bgfxCx1ew0UhjtmAvnjoBHCWj8jNlpJJ/IcoH29ttv07RpU+6++27c3d1xd3enffv23HXXXboHTUREROxHyapQt5tlWV00yWspSdd1zwaqeyaZ5mAYhpGdDQ8ePEh4eDju7u7UrVuXwMDAnM6W78XGxuLr60tMTAw+PppOVUREJM/9eximNAYjBfoug/LBZieSwmLrTPi1P3j6wcDt4OJpdiIxWWZrgyw/By1NtWrVqFatWnY3FxEREcl9JapAve6wfTasGAtP/GR2IikMUpJg5QeW5RYDVZxJlmT5EseuXbsybty4G9aPHz+eRx55JEdCiYiIiOSY1kPBwQkOLYGTm81OI4XB9h/gwjFL96zR02ankXwmywXaypUr6dix4w3rO3TowMqVK3MklIiIiEiOKV4Z6vewLK8Ya24WKfiSE6/rng0CFw9T40j+k+UC7dKlS7i4uNyw3tnZmdjY2BwJJSIiIpKjWg252kX7G05sNDuNFGTbZ8OF4+BZCho9ZXYayYeyXKDVrVuXuXPn3rB+zpw51KpVK0dCiYiIiOSo4pWhgbpoksuSE2Hlh5blO19W90yyJcuThLzxxhs89NBDHD58mLvuuguApUuXMnv2bH76STfeioiIiJ1qNRS2z4HDy+D4BqjQ1OxEUtCEz4KYE+BVBhr1MTuN5FNZ7qDdf//9LFiwgEOHDvHiiy8yZMgQIiIiWLZsGVWrVs2NjCIiIiK3r1hFaPCYZXmFnt0qOSw5EVZ+ZFm+82Vwdjc3j+RbWS7QADp16sSaNWuIi4vjyJEjdOvWjVdeeYX69evndD4RERGRnNPyFXAsAkdWwLF1ZqeRgmTbTIg9aemeBfc2O43kY9kq0MAym2OvXr0oW7YsH330EXfddRfr16/PyWwiIiIiOatYINzxhGVZ96JJTklOgFVXu2ctB4Ozm7l5JF/L0j1oUVFRfPPNN3z11VfExsbSrVs3EhISWLBggSYIERERkfyh5RDY9j0cDYNjayGwudmJJL/b+h3ERoB3WWjYy+w0ks9luoN2//33U6NGDXbs2MHEiRM5deoUkydPzs1sIiIiIjmvaIVrXbTluhdNblPSFVg1wbKs7pnkgEwXaP/73/94+umneeutt+jUqRNOTk65mUtEREQk97QcAo7O8M8q+Ge12WkkP9v6HVw8BT7loGFPs9NIAZDpAm316tVcvHiR4OBgmjZtypQpUzh79mxuZhMRERHJHUUDrv0yvVz3okk2JV2B1dd1z4q4mptHCoRMF2jNmjXjiy++IDIykueee445c+ZQtmxZUlNTWbJkCRcvXszNnCIiIiI5q+UQcHKBY6vh6Cqz00h+tPVbuBgJPuXhjifNTiMFRJZncfT09OSpp55i9erV7Ny5kyFDhvD+++9TqlQpHnjggSwHmDp1KhUrVsTNzY2mTZuycePGDMcmJSUxZswYqlSpgpubG/Xr12fRokU2Yy5evMigQYMIDAzE3d2d5s2bs2nTJpsxly5don///pQvXx53d3dq1arFZ599ZjOmTZs2ODg42Lyef/75LH8/ERERsVO+5a5N6LBiLBiGuXkkf0mKt733TN0zySHZnmYfoEaNGowfP56TJ0/yww8/ZHn7uXPnMnjwYEaNGsXWrVupX78+oaGhnD59Ot3xI0eOZPr06UyePJk9e/bw/PPP06VLF7Zt22Yd07dvX5YsWcLMmTPZuXMn7du3p127dkRERFjHDB48mEWLFjFr1iz27t3LoEGD6N+/P7/++qvN5z3zzDNERkZaX+PHj8/ydxQRERE7dufLV7toa+DoSrPTSH6y5Ru4FAW+AeqeSY5yMAzz/rmoadOmNG7cmClTpgCQmppKQEAAAwYMYPjw4TeML1u2LK+//jr9+vWzruvatSvu7u7MmjWL+Ph4vL29WbhwIZ06dbKOCQ4OpkOHDrzzzjsA1KlTh+7du/PGG29kOKZNmzY0aNCAiRMnZvv7xcbG4uvrS0xMDD4+Ptnej4iIiOSiP4fCxs+hQgj0+R84OJidSOxdUjxMqg+XouG+idCoj9mJJB/IbG1wWx2025GYmMiWLVto167dtTCOjrRr145169alu01CQgJubrZTl7q7u7N6tWX2peTkZFJSUm46BqB58+b8+uuvREREYBgGy5cv58CBA7Rv395mu++//56SJUtSp04dRowYweXLl2/6nRISEoiNjbV5iYiIiJ27czA4ucLxdXBkhdlpJD/YPMNSnPlWgAaPm51GChjTCrSzZ8+SkpJC6dKlbdaXLl2aqKiodLcJDQ1lwoQJHDx40Do5yS+//EJkZCQA3t7ehISE8Pbbb3Pq1ClSUlKYNWsW69ats44BmDx5MrVq1aJ8+fK4uLhw7733MnXqVFq1amUd89hjjzFr1iyWL1/OiBEjmDlzJk888cRNv9PYsWPx9fW1vgICArJ7eERERCSv+Phf64CseF/3osnNJV6G1RMty61egSIupsaRgse0Ai07Jk2aRLVq1QgKCsLFxYX+/fvTp08fHB2vfY2ZM2diGAblypXD1dWVTz75hB49etiMmTx5MuvXr+fXX39ly5YtfPTRR/Tr14+///7bOubZZ58lNDSUunXr8vjjj/Pdd98xf/58Dh8+nGG+ESNGEBMTY32dOHEidw6EiIiI5Kw7X4YibnBiPRxZbnYasWebZ0DcacsDzxs8ZnYaKYBMK9BKliyJk5MT0dHRNuujo6MpU6ZMutv4+fmxYMEC4uLiOHbsGPv27cPLy4vKlStbx1SpUoWwsDAuXbrEiRMn2LhxI0lJSdYx8fHxvPbaa0yYMIH777+fevXq0b9/f7p3786HH36YYd6mTZsCcOjQoQzHuLq64uPjY/MSERGRfMC7DDR6yrK8XDM6SgYS42DNRMtyq6Hg5GxqHCmYTCvQXFxcCA4OZunSpdZ1qampLF26lJCQkJtu6+bmRrly5UhOTubnn3/mwQcfvGGMp6cn/v7+nD9/nsWLF1vHJCUlkZSUZNNRA3ByciI1NTXDzwwPDwfA398/s19RRERE8pMWAy1dtJMb4fDSW4+XwmfTVxB3BopVhPo9zE4jBVQRMz988ODB9OrVi0aNGtGkSRMmTpxIXFwcffpYrgPv2bMn5cqVY+zYsQBs2LCBiIgIGjRoQEREBKNHjyY1NZVhw4ZZ97l48WIMw6BGjRocOnSIoUOHEhQUZN2nj48PrVu3ZujQobi7uxMYGEhYWBjfffcdEyZYnmVx+PBhZs+eTceOHSlRogQ7duzg5ZdfplWrVtSrVy+Pj5KIiIjkCe8y0OhpWD/V0kWrcrdmdJRrEuNgzSTLsrpnkotMLdC6d+/OmTNnePPNN4mKiqJBgwYsWrTIOnHI8ePHbTpdV65cYeTIkRw5cgQvLy86duzIzJkzKVq0qHVMTEwMI0aM4OTJkxQvXpyuXbvy7rvv4ux87T+iOXPmMGLECB5//HHOnTtHYGAg7777rvVB1C4uLvz999/WgjEgIICuXbsycuTIvDkwIiIiYo47B1nuMYrYDIf+hmr3mJ1I7MXGL+DyWShWCeo9anYaKcBMfQ5aQafnoImIiORDi1+HdVOgXDD0XaoumkDCJZhUDy7/C52naXIQyRa7fw6aiIiIiF1qMQicPSBiCxxcYnYasQebvrAUZ8UrQ91uZqeRAk4FmoiIiMj1vPygcV/L8or3NKNjYZdwEdZ8YlluNQycTL1DSAoBFWgiIiIi/9X8JUsX7dQ2OLDY7DRipo2fQ/w5KF4F6j5idhopBFSgiYiIiPyXlx80ecayvELPRSu0rsTC2smW5davqnsmeUIFmoiIiEh6mg8EZ0+IDIf9/zM7jZhh43SIPw8lqkHdh81OI4WECjQRERGR9HiWgKbPWpbVRSt8rsTC2imW5davgqOTuXmk0FCBJiIiIpKR5i+BixdE7YD9f5qdRvLShulw5QKUrA51HjI7jRQiKtBEREREMuJRHJo+Z1lWF63wuBID666790zdM8lDKtBEREREbiakP7h4Q9RO2Pe72WkkL6z/zFKklawBtbuYnUYKGRVoIiIiIjdj00V7H1JTzc0juSv+Aqyballuo+6Z5D0VaCIiIiK3EtIPXH0gehfs+83sNJKb1k+DhBjwqwm11D2TvKcCTURERORWPIpD0+ctyyvGqYtWUMVfsBRocLV7pl+VJe/prBMRERHJjJAXLV2007th769mp5HcsP5TS/esVC2o+aDZaaSQUoEmIiIikhnuxaDZC5blMHXRCpz489e6Z63VPRPz6MwTERERyaxmL4KrL5zeA3sWmJ1GctK6qZAQC6XrQM0HzE4jhZgKNBEREZHMci9qudQRrnbRUkyNIznk8jnL1Pqg7pmYTmefiIiISFY0ewHcfOHMPtg93+w0khPWTYHEi1C6LgTdZ3YaKeRUoImIiIhkhZuv5eHVAGHj1UXL7y6fgw3TLctthqt7JqbTGSgiIiKSVU2fA7eicHa/umj53drJkHgJytSFoE5mpxFRgSYiIiKSZTZdNN2Llm/F/QsbP7cstxkBDg7m5hFBBZqIiIhI9jR9zjL1/tkDsOtns9NIdqz9xNI9868PNTqanUYEUIEmIiIikj1uPrZdtJRkc/NI1sSdhY1fWJbVPRM7ogJNREREJLuaPgfuxeHfQ7DrJ7PTSFasmQRJcVD2Dqh+r9lpRKxUoImIiIhkl6s3NB9gWQ4bry5afnHpDGz60rKs7pnYGRVoIiIiIrejybOWLtq5w7DzR7PTSGasnQRJl6FsQ6jW3uw0IjZUoImIiIjcDlcvaPGSZXmlumh279Jp2KjumdgvFWgiIiIit6vxM+BRAs4dgR1zzU4jN7NmEiTHQ7lGUO0es9OI3EAFmoiIiMjtcvWCFgMtyyvHQ0qSuXkkfRejYdNXlmV1z8ROqUATERERyQmN+4KnH5z/B7bPMTuNpGfNREv3rHxjqHq32WlE0qUCTURERCQnuHhe10X7QF00e3MxCjbPsCyreyZ2TAWaiIiISE5p9LSli3bhGGz/wew0cr3VEyH5CgQ0hSp3mZ1GJEMq0ERERERyiosHtBhkWV75ASQnmhpHroqNvK57NlzdM7FrKtBEREREclKjp8CzFFw4Dttnm51GAFZ/DCkJENAMKrc1O43ITalAExEREclJLh5w58uW5ZUfqotmtthTsOUby3Jb3Xsm9k8FmoiIiEhOa9QHvMpAzAkIn2V2msJt1QRL96xCc6jU2uw0IrekAk1EREQkpzm7X9dF+0hdNLPERMDWby3L6p5JPqECTURERCQ3BPe2dNFiT8K2mWanKZxWT4CURAi8Eyq1MjuNSKaoQBMRERHJDc5u0HKwZXnVR5CcYG6ewibmJGz9zrLcZri5WUSyQAWaiIiISG5p2Au8y0JsxLViQfLGqo8s3bOKLaFSS7PTiGSaCjQRERGR3GLTRZsASVfMzVNYXDgOW69eVtpmhLlZRLJIBZqIiIhIbmrYE3zKwcVT6qLllVUfQWqS5b6zii3MTiOSJSrQRERERHJTEddrXbTV6qLlugvHYdvVRxu0ec3cLCLZoAJNREREJLfd8ST4lIeLkdemfZfcsfJDSE2Gym0gMMTsNCJZpgJNREREJLdd30VbNQGS4s3NU1Cd/wfCv7cs694zyadUoImIiIjkhTueBN8AuBQFW74xO03BZO2etYUKzcxOI5ItKtBERERE8kIRF2g5xLK8+mN10XLauaMQPtuy3Fb3nkn+pQJNREREJK80eBx8K8ClaNg8w+w0BcvKD8FIgSp3Q0ATs9OIZJsKNBEREZG8UsQFWr1iWV49ERIvmxqnwDh3BLb/YFlW90zyORVoIiIiInmpwWNQtALEnVYXLaekdc+q3gPlG5mdRuS2qEATERERyUtOztBqqGV5zURIjDM1Tr7372HYPseyrJkbpQBQgSYiIiKS1+r3gGIVIe4MbPrK7DT528oPLN2zau2hfLDZaURumwo0ERERkbxm00WbpC5adp09BDvmWpbbDDc3i0gOUYEmIiIiYoZ6j0KxSnD5LGz8wuw0+dPKD8BIher3Qjl1z6RgUIEmIiIiYganItB6mGV57SeQcMncPPnN2YOwc55lWd0zKUBUoImIiIiYpW43KF4ZLv8Lm9RFy5Kw8ZbuWY2OUPYOs9OI5BgVaCIiIiJmcSoCra520dZ8AgkXzc2TX5w5ALt+siy3ftXcLCI5TAWaiIiIiJnqPgLFq0D8Odj4udlp8oewcVe7Z52gbAOz04jkKBVoIiIiImZyKnKtC7R2MlyJNTePvTu9D3b9bFnWvWdSAKlAExERETFb3YehRDWIPw8bp5udxr6tHA8YEHQf+NczO41IjlOBJiIiImI2R6frumhT1EXLyOm9sOsXy3KbEeZmEcklphdoU6dOpWLFiri5udG0aVM2btyY4dikpCTGjBlDlSpVcHNzo379+ixatMhmzMWLFxk0aBCBgYG4u7vTvHlzNm3aZDPm0qVL9O/fn/Lly+Pu7k6tWrX47LPPbMZcuXKFfv36UaJECby8vOjatSvR0dE598VFRERErlfnIShZHa5cgA3qoqUrbBxgQM0HoEwds9OI5ApTC7S5c+cyePBgRo0axdatW6lfvz6hoaGcPn063fEjR45k+vTpTJ48mT179vD888/TpUsXtm3bZh3Tt29flixZwsyZM9m5cyft27enXbt2REREWMcMHjyYRYsWMWvWLPbu3cugQYPo378/v/76q3XMyy+/zG+//caPP/5IWFgYp06d4qGHHsq9gyEiIiKF2/VdtHWT4UqMuXnsTfQe2L3AsqyZG6UAczAMwzDrw5s2bUrjxo2ZMmUKAKmpqQQEBDBgwACGD7/xps+yZcvy+uuv069fP+u6rl274u7uzqxZs4iPj8fb25uFCxfSqVMn65jg4GA6dOjAO++8A0CdOnXo3r07b7zxRrpjYmJi8PPzY/bs2Tz88MMA7Nu3j5o1a7Ju3TqaNWuWqe8XGxuLr68vMTEx+Pj4ZP0AiYiISOGSmgKfhsDZ/dDmNWijQsRqXk/YsxBqPQjdvjM7jUiWZbY2MK2DlpiYyJYtW2jXrt21MI6OtGvXjnXr1qW7TUJCAm5ubjbr3N3dWb16NQDJycmkpKTcdAxA8+bN+fXXX4mIiMAwDJYvX86BAwdo3749AFu2bCEpKckmW1BQEBUqVMgwW1q+2NhYm5eIiIhIpjk6XSvK1k2F+AumxrEbUbssxRkO0FozN0rBZlqBdvbsWVJSUihdurTN+tKlSxMVFZXuNqGhoUyYMIGDBw+SmprKkiVL+OWXX4iMjATA29ubkJAQ3n77bU6dOkVKSgqzZs1i3bp11jEAkydPplatWpQvXx4XFxfuvfdepk6dSqtWrQCIiorCxcWFokWLZjobwNixY/H19bW+AgICsnNoREREpDCr1QX8akJCDKyfZnYa+xA2zvKzdmcoXcvUKCK5zfRJQrJi0qRJVKtWjaCgIFxcXOjfvz99+vTB0fHa15g5cyaGYVCuXDlcXV355JNP6NGjh82YyZMns379en799Ve2bNnCRx99RL9+/fj7779vK9+IESOIiYmxvk6cOHFb+xMREZFCyNHxWhdt/TR10aJ2wt5fUfdMCgvTCrSSJUvi5OR0w8yI0dHRlClTJt1t/Pz8WLBgAXFxcRw7dox9+/bh5eVF5cqVrWOqVKlCWFgYly5d4sSJE2zcuJGkpCTrmPj4eF577TUmTJjA/fffT7169ejfvz/du3fnww8/BKBMmTIkJiZy4cKFTGcDcHV1xcfHx+YlIiIikmU1H4RSta520T41O425Vrxv+VnnISgVZG4WkTxgWoHm4uJCcHAwS5cuta5LTU1l6dKlhISE3HRbNzc3ypUrR3JyMj///DMPPvjgDWM8PT3x9/fn/PnzLF682DomKSmJpKQkm44agJOTE6mpqYBlwhBnZ2ebbPv37+f48eO3zCYiIiJy2xwdr81UuH6a5QHWhVHkDtj3O+AArYaZnUYkTxQx88MHDx5Mr169aNSoEU2aNGHixInExcXRp08fAHr27Em5cuUYO3YsABs2bCAiIoIGDRoQERHB6NGjSU1NZdiwa//BLl68GMMwqFGjBocOHWLo0KEEBQVZ9+nj40Pr1q0ZOnQo7u7uBAYGEhYWxnfffceECRMA8PX15emnn2bw4MEUL14cHx8fBgwYQEhISKZncBQRERG5LTUfgNJ1IHqXZcKQu0aanSjvWbtnXdU9k0LD1AKte/funDlzhjfffJOoqCgaNGjAokWLrBOHHD9+3KbTdeXKFUaOHMmRI0fw8vKiY8eOzJw502Yyj5iYGEaMGMHJkycpXrw4Xbt25d1338XZ2dk6Zs6cOYwYMYLHH3+cc+fOERgYyLvvvsvzzz9vHfPxxx/j6OhI165dSUhIIDQ0lE8/LeSXGIiIiEjeSeuizXsS1n8GzV4Ej+Jmp8o7p8Jh/x/g4KjnnkmhYupz0Ao6PQdNREREbktqKkxvBdE7oeUQuPtNsxPlnR96wP4/oW436PqF2WlEbpvdPwdNRERERG7B0RHaXJ25cMN0uHzO3Dx55dQ2S3Gm7pkUQirQREREROxZUCcoUxcSL8HayWanyRtp957V7QYlq5qbRSSPqUATERERsWcODtBmhGV54+cQ96+5eXJbxBY4sMjSPWs11Ow0InlOBZqIiIiIvavREfzrX+2ifWJ2mtyV1j2r113dMymUVKCJiIiI2DubLtoXEHfW3Dy55eRmOPgXODipeyaFlgo0ERERkfyg+r1Q9g5IioM1k8xOkzvSumf1H4USVczNImISFWgiIiIi+cH1XbRNX8KlM+bmyWknNsGhJVe7Z6+YnUbENCrQRERERPKLau2hbENIugxrC1gXbcVYy8/6PaB4ZXOziJhIBZqIiIhIfmFzL9qXcOm0uXlyyomNcHgpOBZR90wKPRVoIiIiIvlJtXugXCNIji8496Itf8/ys34PKF7J3CwiJlOBJiIiIpKf2NyL9hVcjDY3z+06vh6OLL/aPdPMjSIq0ERERETym6p3Q/nGBaOLlnbvWYPHoViguVlE7IAKNBEREZH85vou2uav4GKUuXmy69g6OLJC956JXEcFmoiIiEh+VOUuCGgKyVdg9USz02TPiqv3nt3xBBStYG4WETuhAk1EREQkP3JwgDbDLcubZ0BspLl5suqfNXB0JTg6Q0t1z0TSqEATERERya8qt4WAZpCSAKs/NjtN1qTde9bwSSgaYG4WETuiAk1EREQkv3JwgLZX70Xb8g3EnjI1TqYdXQX/rAInF2g5xOw0InZFBZqIiIhIflapNVRonr+6aCvet/xs2BN8y5ubRcTOqEATERERyc/+20WLiTA1zi0dXQnHVlu6Z3cONjuNiN1RgSYiIiKS31VqBYF3QkoirJ5gdpqMGQYsT7v3rBf4ljM3j4gdUoEmIiIiUhCkzei49TuIOWlulowcDYPja8HJFVqqeyaSHhVoIiIiIgVBpZZQsaWli7bqI7PT3Oj67llwb/Apa2ocEXulAk1ERESkoGhz9V60rTPhwnFzs/zXkeVwYj0UcYM7XzY7jYjdUoEmIiIiUlBUbGG5Hy01CVbZ0b1ohnFt5sbgPuDjb24eETumAk1ERESkIEnrom2bZT9dtMPL4MSGq92zQWanEbFrRcwOIJCSkkJSUpLZMaQAcnFxwdFR/w4jIlKoBDa3PBvtaBis/BAe+MTcPIYBK67ee9boKfAuY24eETunAs1EhmEQFRXFhQsXzI4iBZSjoyOVKlXCxcXF7CgiIpKX2r5mKdDCv7fMllisonlZDi2Fk5ugiDu0GGReDpF8QgWaidKKs1KlSuHh4YGDg4PZkaQASU1N5dSpU0RGRlKhQgWdXyIihUmFZlC5rWVijpUfwoNTzMlhGLDiPcty46fBu7Q5OUTyERVoJklJSbEWZyVKlDA7jhRQfn5+nDp1iuTkZJydnc2OIyIieanta5YCLXw2tBwCxSvlfYaDSyBiy9Xu2cC8/3yRfEg3p5gk7Z4zDw8Pk5NIQZZ2aWNKSorJSUREJM8FNIEqd4ORAqs+zPvPv/7esyZ9watU3mcQyYdUoJlMl51JbtL5JSJSyKXN6Bj+A5w7krefffAvOLUVnD2gubpnIpmlAk1ERESkoApoDFXbWbpoK/Owi3Z996xxX/Dyy7vPFsnnVKDlcympBusO/8vC8AjWHf6XlFTD7Ei5ysHBgQULFpgdQ0REJP9o85rl5/Y58O/hvPnMA4vg1DZw9tS9ZyJZpAItH1u0K5I7xy2jxxfrGTgnnB5frOfOcctYtCsy1z6zd+/eODg44ODggLOzM5UqVWLYsGFcuXIl1z7THlz/va9/HTp0yNRMnTt3Nu3zRUQknygfDNXaX+2ifZD7n2dz79kz4Fky9z9TpABRgZZPLdoVyQuzthIZY1sYRcVc4YVZW3O1SLv33nuJjIzkyJEjfPzxx0yfPp1Ro0bl2ufZi7Tvff2rUqXszYiVmJiYw+lERERuos1wy88dc+FsLv/j4v4/IXI7uHhB85dy97NECiAVaHbCMAwuJyZn6nXxShKjft1Nehczpq0b/eseLl5JytT+DCNrl0W6urpSpkwZAgIC6Ny5M+3atWPJkiXW9//991969OhBuXLl8PDwoG7duvzwww82+2jTpg0vvfQSw4YNo3jx4pQpU4bRo0fbjDl48CCtWrXCzc2NWrVq2XxGmp07d3LXXXfh7u5OiRIlePbZZ7l06ZL1/bQu03vvvUfp0qUpWrQoY8aMITk5maFDh1K8eHHKly/P119/nenvff3LyckJgLCwMJo0aYKrqyv+/v4MHz6c5ORkm+/bv39/Bg0aRMmSJQkNDQVg165ddOjQAS8vL0qXLs2TTz7J2bNnrdv99NNP1K1b1/r92rVrR1xcHKNHj+bbb79l4cKF1m7eihUrbvkdRESkkCoXDNXvBSM1d7toNt2zZ8FTjxISySo9B81OxCelUOvNxTmyLwOIir1C3dF/ZWr8njGheLhk71TYtWsXa9euJTAw0LruypUrBAcH8+qrr+Lj48Mff/zBk08+SZUqVWjSpIl13LfffsvgwYPZsGED69ato3fv3rRo0YJ77rmH1NRUHnroIUqXLs2GDRuIiYlh0KBBNp8dFxdHaGgoISEhbNq0idOnT9O3b1/69+/PN998Yx23bNkyypcvz8qVK1mzZg1PP/00a9eupVWrVmzYsIG5c+fy3HPPcc8991C+fPksH4OIiAg6duxI7969+e6779i3bx/PPPMMbm5uNkXnt99+ywsvvMCaNWsAuHDhAnfddRd9+/bl448/Jj4+nldffZVu3bqxbNkyIiMj6dGjB+PHj6dLly5cvHiRVatWYRgGr7zyCnv37iU2NtZaXBYvXjzL2UVEpBBpM9xyb9jOedDqFShZLec/Y98fELXzavdsQM7vX6QQUIEmWfb777/j5eVFcnIyCQkJODo6MmXKFOv75cqV45VXXrH+ecCAASxevJh58+bZFGj16tWzXhpZrVo1pkyZwtKlS7nnnnv4+++/2bdvH4sXL6Zs2bIAvPfee3To0MG6/ezZs7ly5Qrfffcdnp6eAEyZMoX777+fcePGUbp0acBSuHzyySc4OjpSo0YNxo8fz+XLl3ntNctN0yNGjOD9999n9erVPProo7f83mk6dOjAjz/+yKeffkpAQABTpkzBwcGBoKAgTp06xauvvsqbb76Jo6Oj9TuOHz/euv0777zDHXfcwXvvvWddN2PGDAICAjhw4ACXLl0iOTmZhx56yFoA161b1zrW3d2dhIQEypQpc/P/wURERADK3gHVO8CB/0HYeOj6Rc7uPzUVVrxvWW76HHjoHw5FskMFmp1wd3Ziz5jQTI3dePQcvb/edMtx3/RpTJNKt/7L0d3ZKVOfm6Zt27ZMmzaNuLg4Pv74Y4oUKULXrl2t76ekpPDee+8xb948IiIiSExMJCEh4YaHcterV8/mz/7+/pw+fRqAvXv3EhAQYC3OAEJCQmzG7927l/r161uLM4AWLVqQmprK/v37rQVa7dq1rUUSQOnSpalTp471z05OTpQoUcL62bf63mnSPnfv3r2EhITYPHOsRYsWXLp0iZMnT1KhQgUAgoODbfa3fft2li9fblP0pTl8+DDt27fn7rvvpm7duoSGhtK+fXsefvhhihUrdtOcIiIiGWoz3FKg7foJWg0Fv+o5t+99v0P0TnDxhpD+ObdfkUJGBZqdcHBwyPRlhi2r+eHv60ZUzJV070NzAMr4utGymh9Ojjn/oGJPT0+qVq0KWDo+9evX56uvvuLpp58G4IMPPmDSpElMnDiRunXr4unpyaBBg26YGMPZ2dk2t4MDqampOZ43vc/Jzmdf/72z4/pCEuDSpUvWbt9/+fv74+TkxJIlS1i7di1//fUXkydP5vXXX2fDhg3ZnpxEREQKubINoEYn2P8HhI2Dh7/Kmf1e3z1r9ry6ZyK3QZOE5ENOjg6Mur8WYCnGrpf251H318qV4uy/HB0dee211xg5ciTx8fEArFmzhgcffJAnnniC+vXrU7lyZQ4cOJCl/dasWZMTJ04QGXltNsr169ffMGb79u3ExcVZ161Zs8Z6KWNeqVmzJuvWrbOZbGXNmjV4e3vf9J62hg0bsnv3bipWrEjVqlVtXmnFnIODAy1atOCtt95i27ZtuLi4MH/+fABcXFxISUnJ3S8nIiIFT9qMjrt+htP7cmafe3+F07vB1QdC+uXMPkUKKRVo+dS9dfyZ9kRDyvi62awv4+vGtCcacm8d/zzL8sgjj+Dk5MTUqVMBy71WaZ2fvXv38txzzxEdHZ2lfbZr147q1avTq1cvtm/fzqpVq3j99ddtxjz++OO4ubnRq1cvdu3axfLlyxkwYABPPvmk9fLGvPDiiy9y4sQJBgwYwL59+1i4cCGjRo1i8ODBNpdW/le/fv04d+4cPXr0YNOmTRw+fJjFixfTp08fUlJS2LBhA++99x6bN2/m+PHj/PLLL5w5c4aaNWsCULFiRXbs2MH+/fs5e/YsSUlJefWVRUQkP/OvB0H3AQasHH/L4beUmmrpxgE0ewHcdSm+yO1QgZaP3VvHn9Wv3sUPzzRj0qMN+OGZZqx+9a48Lc4AihQpQv/+/Rk/fjxxcXGMHDmShg0bEhoaSps2bShTpkyWH6js6OjI/PnziY+Pp0mTJvTt25d3333XZoyHhweLFy/m3LlzNG7cmIcffpi7777bZsKSvFCuXDn+/PNPNm7cSP369Xn++ed5+umnGTly5E23K1u2LGvWrCElJYX27dtTt25dBg0aRNGiRXF0dMTHx4eVK1fSsWNHqlevzsiRI/noo4+sE6U888wz1KhRg0aNGuHn52edHVJEROSWrF20X+D03tvb196FcHoPuPpCsxdvP5tIIedgZPUhWJJpsbGx+Pr6EhMTg4+Pj817V65c4ejRo1SqVAk3N7cM9iBye3SeiYhIhuY+AXt/g9pd4JFvsreP1FSY1hzO7IXWw6HtiByNKFKQ3Kw2uJ46aCIiIiKFUeurXbTdCyB6T/b2sWe+pThz9bVc3igit00FmoiIiEhhVKYO1HoQMCDs/axvn5oCK67eexbSD9yL5mQ6kUJLBZqIiIhIYdV6OOAAexZC1K6sbbt7PpzdD26+lqn1RSRHqEATERERKaxK14LanS3LYTc+lzNDqSnXxocMsBRpIpIjVKCJiIiIFGatXwUcLM8yi9qZuW12/QJnD4BbUWj6XG6mEyl0VKCJiIiIFGalalpmcgRYkYl70a7vnjXvD24Zz0YnIlmnAk1ERESksEvrou37HSJ33Hzszp/g34OWB1I3UfdMJKepQBMREREp7EoFQZ2uluWbddFSkq/rng1Q90wkF6hAExERERFLF83BEfb/AafC0x+z80c4dxjci0OTZ/M0nkhhUcTsAJJNF07A5X8zft+jBBQNyLs8IiIikr/5VYc6D8POeZYuWY8fbN9PSYaV4y3LLV4CV++8zyhSCKiDlh9dOAFTguHz1hm/pgRbxuWwlJQUmjdvzkMPPWSzPiYmhoCAAF5//XXrup9//pm77rqLYsWK4e7uTo0aNXjqqafYtm2bdcw333yDg4OD9eXl5UVwcDC//PJLjme/mTZt2jBo0KA8/UwRERG703rY1S7an3Bqm+17O+fBuSOWfwRu/Iw5+UQKARVo+dHlfyE54eZjkhNu3mHLJicnJ7755hsWLVrE999/b10/YMAAihcvzqhRowB49dVX6d69Ow0aNODXX39l//79zJ49m8qVKzNixAibffr4+BAZGUlkZCTbtm0jNDSUbt26sX///hzPLyIiIjdRshrUfcSyfP29aCnJEHa1e9b8JXD1yvtsIoWECjR7YRiQGJe5V3J85vaZHJ+5/RlGlqJWr16d999/nwEDBhAZGcnChQuZM2cO3333HS4uLqxfv57x48czYcIEJkyYQMuWLalQoQLBwcGMHDmS//3vfzb7c3BwoEyZMpQpU4Zq1arxzjvv4OjoyI4d12aROn/+PD179qRYsWJ4eHjQoUMHDh48aLOfn3/+mdq1a+Pq6krFihX56KOPbN7/9NNPqVatGm5ubpQuXZqHH34YgN69exMWFsakSZOsnbx//vknS8dERESkwLjjScABDiyC7T9Y7kdbOR7OH7U896xGB5MDihRsugfNXiRdhvfK5uw+Z9ybuXGvnQIXzyztesCAAcyfP58nn3ySnTt38uabb1K/fn0AfvjhB7y8vHjxxRfT3dbBwSHD/aakpPDdd98B0LBhQ+v63r17c/DgQX799Vd8fHx49dVX6dixI3v27MHZ2ZktW7bQrVs3Ro8eTffu3Vm7di0vvvgiJUqUoHfv3mzevJmXXnqJmTNn0rx5c86dO8eqVasAmDRpEgcOHKBOnTqMGTMGAD8/vywdDxERkQLhwgn4vitw9R9v5z9v+/6VCzC9JfTfonvdRXKJCjTJFgcHB6ZNm0bNmjWpW7cuw4cPt7534MABKleuTJEi106vCRMm8Oabb1r/HBERga+vL2C5f83Ly3KpRHx8PM7Oznz++edUqVIFwFqYrVmzhubNmwPw/fffExAQwIIFC3jkkUeYMGECd999N2+88QZg6fLt2bOHDz74gN69e3P8+HE8PT2577778Pb2JjAwkDvuuAMAX19fXFxc8PDwoEyZMrl41EREROxcVm6jUIEmkivs4hLHqVOnUrFiRdzc3GjatCkbN27McGxSUhJjxoyhSpUquLm5Ub9+fRYtWmQz5uLFiwwaNIjAwEDc3d1p3rw5mzZtshlz/cQU178++OAD65iKFSve8P7779/k2SC3w9nD0snKzOupRbfeH1jGZWZ/zh7Zijxjxgw8PDw4evQoJ0+evHmUp54iPDyc6dOnExcXh3HdZZXe3t6Eh4cTHh7Otm3beO+993j++ef57bffANi7dy9FihShadOm1m1KlChBjRo12Lt3r3VMixYtbD6zRYsWHDx4kJSUFO655x4CAwOpXLkyTz75JN9//z2XL1/O1vcWEREREcktphdoc+fOZfDgwYwaNYqtW7dSv359QkNDOX36dLrjR44cyfTp05k8eTJ79uzh+eefp0uXLjYzA/bt25clS5Ywc+ZMdu7cSfv27WnXrh0RERHWMWmTUqS9ZsyYgYODA127drX5vDFjxtiMGzBgQO4cCAcHy2WGmXkVcc/cPou4Z25/N7nkMCNr167l448/5vfff6dJkyY8/fTT1qKrWrVqHDlyhKSkJOv4okWLUrVqVcqVK3fDvhwdHalatSpVq1alXr16DB48mDZt2jBu3Lgs58qIt7c3W7du5YcffsDf3996SeaFCxdy7DNERERERG6X6QXahAkTeOaZZ+jTpw+1atXis88+w8PDgxkzZqQ7fubMmbz22mt07NiRypUr88ILL9CxY0frhBDx8fH8/PPPjB8/nlatWlG1alVGjx5N1apVmTZtmnU/aZNSpL0WLlxI27ZtqVy5ss3neXt724zz9MzavVoF0eXLl+nduzcvvPACbdu25auvvmLjxo189tlnAPTo0YNLly7x6aefZvsznJyciI+3TIZSs2ZNkpOT2bBhg/X9f//9l/3791OrVi3rmDVr1tjsY82aNVSvXh0nJycAihQpQrt27Rg/fjw7duzgn3/+YdmyZQC4uLiQkpKS7bwiIiIiIjnB1AItMTGRLVu20K5dO+s6R0dH2rVrx7p169LdJiEhATc3N5t17u7urF69GoDk5GRSUlJuOua/oqOj+eOPP3j66adveO/999+nRIkS3HHHHXzwwQckJydn+H0SEhKIjY21eeUKjxJQxPXmY4q4WsblghEjRmAYhvVyz4oVK/Lhhx8ybNgw/vnnH0JCQhgyZAhDhgxh8ODBrF69mmPHjrF+/Xq++uorHBwccHS8duoZhkFUVBRRUVEcPXqUzz//nMWLF/Pggw8Clo7cgw8+yDPPPMPq1avZvn07TzzxBOXKlbOOGTJkCEuXLuXtt9/mwIEDfPvtt0yZMoVXXnkFgN9//51PPvmE8PBwjh07xnfffUdqaio1atSwfocNGzbwzz//cPbsWVJTU3Pl2ImIiIiI3JRhooiICAMw1q5da7N+6NChRpMmTdLdpkePHkatWrWMAwcOGCkpKcZff/1luLu7Gy4uLtYxISEhRuvWrY2IiAgjOTnZmDlzpuHo6GhUr1493X2OGzfOKFasmBEfH2+z/qOPPjKWL19ubN++3Zg2bZpRtGhR4+WXX87w+4waNcrAMu2RzSsmJuaGsfHx8caePXtu+MxMO3/cMCK2Zfw6fzx7+72FFStWGE5OTsaqVatueK99+/bGXXfdZaSmphqGYRhz58412rRpY/j6+hrOzs5G+fLljccee8xYv369dZuvv/7a5li5uroa1atXN959910jOTnZOu7cuXPGk08+afj6+hru7u5GaGioceDAAZvP/+mnn4xatWoZzs7ORoUKFYwPPvjA+t6qVauM1q1bG8WKFTPc3d2NevXqGXPnzrW+v3//fqNZs2aGu7u7ARhHjx7NqUNmqts+z0REpHCJ2GYYo3xu/YrYZnZSkXwnJiYmw9rgeg6GkcWHYOWgU6dOUa5cOdauXUtISIh1/bBhwwgLC7O5pC3NmTNneOaZZ/jtt99wcHCgSpUqtGvXjhkzZlgviTt8+DBPPfUUK1euxMnJiYYNG1K9enW2bNlinVTiekFBQdxzzz1Mnjz5pnlnzJjBc889x6VLl3B1vbGDlZCQQELCtZmPYmNjCQgIICYmBh8fH5uxV65c4ejRo1SqVOmGbp9ITtF5JiIiWXIqHD5vfetxz4ZB2Qa5nUakQImNjcXX1zfd2uB6pl7iWLJkSZycnIiOjrZZHx0dneF0535+fixYsIC4uDiOHTvGvn378PLysrl3rEqVKoSFhXHp0iVOnDjBxo0bSUpKuuH+MoBVq1axf/9++vbte8u8TZs2JTk5OcOHGLu6uuLj42PzEhEREck3TL6NQkRMfg6ai4sLwcHBLF26lM6dOwOQmprK0qVL6d+//023dXNzo1y5ciQlJfHzzz/TrVu3G8Z4enri6enJ+fPnWbx4MePHj79hzFdffUVwcLD1Ics3Ex4ejqOjI6VKlcrcFxQRERHJT4oGWB5CffnfjMd4lNAz0ERykekPqh48eDC9evWiUaNGNGnShIkTJxIXF0efPn0A6NmzJ+XKlWPs2LEAbNiwgYiICBo0aEBERASjR48mNTWVYcOGWfe5ePFiDMOgRo0aHDp0iKFDhxIUFGTdZ5rY2Fh+/PFH6wyQ11u3bh0bNmygbdu2eHt7s27dOl5++WWeeOIJihUrlotHRERERMRERQNUgImYyPQCrXv37pw5c4Y333yTqKgoGjRowKJFiyhdujQAx48ft5nx78qVK4wcOZIjR47g5eVFx44dmTlzJkWLFrWOiYmJYcSIEZw8eZLixYvTtWtX3n33XZydnW0+e86cORiGQY8ePW7I5erqypw5cxg9ejQJCQlUqlSJl19+mcGDB+fOgRARERERkULP1ElCCrqb3QiYNnlDxYoVcXfP5IOnRbIoPj6ef/75R5OEiIiIiJgsX0wSUpildfMuX75schIpyBITEwGsD+sWEREREftm+iWOhZWTkxNFixbl9OnTAHh4eODg4GByKilIUlNTOXPmDB4eHhQpov/URURERPID/dZmorRHCaQVaSI5zdHRkQoVKqj4FxEREcknVKCZyMHBAX9/f0qVKkVSUpLZcaQAcnFxsZlkR0RERETsmwo0O+Dk5KR7hERERERERJOEiIiIiIiI2AsVaCIiIiIiInZCBZqIiIiIiIid0D1ouSjtGeCxsbEmJxERERERETOl1QRpNUJGVKDloosXLwIQEBBgchIREREREbEHFy9exNfXN8P3HYxblXCSbampqZw6dQpvb2/Tn0MVGxtLQEAAJ06cwMfHx9QsBZGOb+7S8c1dOr65S8c3d+n45i4d39yl45v77OkYG4bBxYsXKVu27E0fg6QOWi5ydHSkfPnyZsew4ePjY/rJWZDp+OYuHd/cpeObu3R8c5eOb+7S8c1dOr65z16O8c06Z2k0SYiIiIiIiIidUIEmIiIiIiJiJ1SgFRKurq6MGjUKV1dXs6MUSDq+uUvHN3fp+OYuHd/cpeObu3R8c5eOb+7Lj8dYk4SIiIiIiIjYCXXQRERERERE7IQKNBERERERETuhAk1ERERERMROqEATERERERGxEyrQCoiVK1dy//33U7ZsWRwcHFiwYMEtt1mxYgUNGzbE1dWVqlWr8s033+R6zvwqq8d3xYoVODg43PCKiorKm8D5yNixY2ncuDHe3t6UKlWKzp07s3///ltu9+OPPxIUFISbmxt169blzz//zIO0+U92ju8333xzw7nr5uaWR4nzl2nTplGvXj3rA1BDQkL43//+d9NtdO5mXlaPr87d2/P+++/j4ODAoEGDbjpO53D2ZOb46hzOmtGjR99wvIKCgm66TX44f1WgFRBxcXHUr1+fqVOnZmr80aNH6dSpE23btiU8PJxBgwbRt29fFi9enMtJ86esHt80+/fvJzIy0voqVapULiXMv8LCwujXrx/r169nyZIlJCUl0b59e+Li4jLcZu3atfTo0YOnn36abdu20blzZzp37syuXbvyMHn+kJ3jC+Dj42Nz7h47diyPEucv5cuX5/3332fLli1s3ryZu+66iwcffJDdu3enO17nbtZk9fiCzt3s2rRpE9OnT6devXo3HadzOHsye3xB53BW1a5d2+Z4rV69OsOx+eb8NaTAAYz58+ffdMywYcOM2rVr26zr3r27ERoamovJCobMHN/ly5cbgHH+/Pk8yVSQnD592gCMsLCwDMd069bN6NSpk826pk2bGs8991xux8v3MnN8v/76a8PX1zfvQhUwxYoVM7788st039O5e/tudnx17mbPxYsXjWrVqhlLliwxWrdubQwcODDDsTqHsy4rx1fncNaMGjXKqF+/fqbH55fzVx20QmrdunW0a9fOZl1oaCjr1q0zKVHB1KBBA/z9/bnnnntYs2aN2XHyhZiYGACKFy+e4Ridv9mXmeMLcOnSJQIDAwkICLhlx0IsUlJSmDNnDnFxcYSEhKQ7Rudu9mXm+ILO3ezo168fnTp1uuHcTI/O4azLyvEFncNZdfDgQcqWLUvlypV5/PHHOX78eIZj88v5W8TsAGKOqKgoSpcubbOudOnSxMbGEh8fj7u7u0nJCgZ/f38+++wzGjVqREJCAl9++SVt2rRhw4YNNGzY0Ox4dis1NZVBgwbRokUL6tSpk+G4jM5f3eN3c5k9vjVq1GDGjBnUq1ePmJgYPvzwQ5o3b87u3bspX758HibOH3bu3ElISAhXrlzBy8uL+fPnU6tWrXTH6tzNuqwcX527WTdnzhy2bt3Kpk2bMjVe53DWZPX46hzOmqZNm/LNN99Qo0YNIiMjeeutt2jZsiW7du3C29v7hvH55fxVgSaSC2rUqEGNGjWsf27evDmHDx/m448/ZubMmSYms2/9+vVj165dN71+XLIvs8c3JCTEpkPRvHlzatasyfTp03n77bdzO2a+U6NGDcLDw4mJieGnn36iV69ehIWFZVhESNZk5fjq3M2aEydOMHDgQJYsWaKJKHJBdo6vzuGs6dChg3W5Xr16NG3alMDAQObNm8fTTz9tYrLbowKtkCpTpgzR0dE266Kjo/Hx8VH3LJc0adJEhcdN9O/fn99//52VK1fe8l8JMzp/y5Qpk5sR87WsHN//cnZ25o477uDQoUO5lC5/c3FxoWrVqgAEBwezadMmJk2axPTp028Yq3M367JyfP9L5+7NbdmyhdOnT9tc2ZGSksLKlSuZMmUKCQkJODk52WyjczjzsnN8/0vncNYULVqU6tWrZ3i88sv5q3vQCqmQkBCWLl1qs27JkiU3va5fbk94eDj+/v5mx7A7hmHQv39/5s+fz7Jly6hUqdItt9H5m3nZOb7/lZKSws6dO3X+ZlJqaioJCQnpvqdz9/bd7Pj+l87dm7v77rvZuXMn4eHh1lejRo14/PHHCQ8PT7d40Dmcedk5vv+lczhrLl26xOHDhzM8Xvnm/DV7lhLJGRcvXjS2bdtmbNu2zQCMCRMmGNu2bTOOHTtmGIZhDB8+3HjyySet448cOWJ4eHgYQ4cONfbu3WtMnTrVcHJyMhYtWmTWV7BrWT2+H3/8sbFgwQLj4MGDxs6dO42BAwcajo6Oxt9//23WV7BbL7zwguHr62usWLHCiIyMtL4uX75sHfPkk08aw4cPt/55zZo1RpEiRYwPP/zQ2Lt3rzFq1CjD2dnZ2Llzpxlfwa5l5/i+9dZbxuLFi43Dhw8bW7ZsMR599FHDzc3N2L17txlfwa4NHz7cCAsLM44ePWrs2LHDGD58uOHg4GD89ddfhmHo3L1dWT2+Ondv339nGdQ5nLNudXx1DmfNkCFDjBUrVhhHjx411qxZY7Rr184oWbKkcfr0acMw8u/5qwKtgEib1v2/r169ehmGYRi9evUyWrdufcM2DRo0MFxcXIzKlSsbX3/9dZ7nzi+yenzHjRtnVKlSxXBzczOKFy9utGnTxli2bJk54e1cescVsDkfW7dubT3WaebNm2dUr17dcHFxMWrXrm388ccfeRs8n8jO8R00aJBRoUIFw8XFxShdurTRsWNHY+vWrXkfPh946qmnjMDAQMPFxcXw8/Mz7r77bmvxYBg6d29XVo+vzt3b998CQudwzrrV8dU5nDXdu3c3/P39DRcXF6NcuXJG9+7djUOHDlnfz6/nr4NhGEbe9etEREREREQkI7oHTURERERExE6oQBMREREREbETKtBERERERETshAo0ERERERERO6ECTURERERExE6oQBMREREREbET/2/nblqp2+MwAP/2g9ihTDx5jxLbyECUDDBDmfgEu7xGJBMGwkcwUEZSygdQYigDyS5jL5l5GRgZGCpnpiPnOaWcbR1dV63B+rXW6v4P7/5rLQUNAAAgIRQ0AACAhFDQACBP+vr6Yn5+/l+vaWxsjPX19bzkASB5FDQA+IRsNhupVOrDcXNz893RAPgBCr87AAD83wwMDMT29va7WWVl5TelAeAnsYMGAJ9UXFwcVVVV746CgoI4Pj6Orq6uKC4ujurq6lhaWoqXl5c/Pufx8TGGh4cjnU5HU1NT7O7u5nEVACSRHTQA+AL39/cxNDQU2Ww2dnZ24vLyMsbHx6OkpCTW1tb+8Z5sNhsPDw9xdHQURUVFMTc3F4+Pj/kNDkCiKGgA8En7+/tRVlb2dj44OBgtLS1RX18fGxsbkUqlIpPJxMPDQywuLsbKykr8+vX+pZXr6+s4PDyMXC4XnZ2dERGxtbUVbW1teV0LAMmioAHAJ/X398fm5ubbeWlpaczMzER3d3ekUqm3eU9PTzw/P8fd3V00NDS8e8bFxUUUFhZGR0fH2yyTyURFRcV/nh+A5FLQAOCTSktLo7m5+btjAPAD+UkIAHyBtra2OD09jdfX17fZyclJlJeXR11d3YfrM5lMvLy8xPn5+dvs6uoqnp6e8hEXgIRS0ADgC0xPT8ft7W3Mzs7G5eVl7O3txerqaiwsLHz4/iwiorW1NQYGBmJycjLOzs7i/Pw8xsbGIp1Of0N6AJJCQQOAL1BbWxsHBweRy+Wivb09pqamYnR0NJaXl/94z/b2dtTU1ERvb2+MjIzExMRE/P79O4+pAUia1Ovf38UAAADg29hBAwAASAgFDQAAICEUNAAAgIRQ0AAAABJCQQMAAEgIBQ0AACAhFDQAAICEUNAAAAASQkEDAABICAUNAAAgIRQ0AACAhPgLe5cqLsUAbrQAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Updated Random Forest Accuracy: 1.0\n",
            "Updated XGBoost Accuracy: 0.9980119284294234\n"
          ]
        }
      ],
      "source": [
        "# Evaluasi dengan Cross-Validation untuk Random Forest\n",
        "cv_scores_rf = cross_val_score(best_rf_model, X_train, y_train, cv=5)\n",
        "print(f\"Random Forest Cross-Validation Accuracy: {np.mean(cv_scores_rf):.4f} +/- {np.std(cv_scores_rf):.4f}\")\n",
        "\n",
        "# Evaluasi dengan Cross-Validation untuk XGBoost\n",
        "cv_scores_xgb = cross_val_score(best_xgb_model, X_train, y_train, cv=5)\n",
        "print(f\"XGBoost Cross-Validation Accuracy: {np.mean(cv_scores_xgb):.4f} +/- {np.std(cv_scores_xgb):.4f}\")\n",
        "\n",
        "# Plot Cross-Validation Scores\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range(1, 6), cv_scores_rf, marker='o', label='Random Forest')\n",
        "plt.plot(range(1, 6), cv_scores_xgb, marker='s', label='XGBoost')\n",
        "plt.xlabel('Fold')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Cross-Validation Accuracy per Fold')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Reduksi Overfitting dengan Pruning Random Forest\n",
        "best_rf_model.set_params(n_estimators=50, max_depth=10, min_samples_split=5, min_samples_leaf=2)\n",
        "best_rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Reduksi Overfitting dengan Regularisasi XGBoost\n",
        "best_xgb_model.set_params(n_estimators=50, max_depth=6, learning_rate=0.1, reg_lambda=1.0)\n",
        "best_xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluasi ulang setelah overfitting ditangani\n",
        "y_pred_rf_new = best_rf_model.predict(X_test)\n",
        "y_pred_xgb_new = best_xgb_model.predict(X_test)\n",
        "\n",
        "print(\"Updated Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf_new))\n",
        "print(\"Updated XGBoost Accuracy:\", accuracy_score(y_test, y_pred_xgb_new))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **1. Perbandingan Hasil Evaluasi Sebelum dan Setelah Tuning**  \n",
        "- **Sebelum Tuning:**  \n",
        "  - Model Random Forest dan XGBoost menunjukkan **akurasi sangat tinggi** bahkan sebelum dilakukan tuning, masing-masing dengan akurasi 100% dan ~99.80%.  \n",
        "  - Meskipun terlihat ideal, hasil ini berpotensi menunjukkan **indikasi overfitting**, karena belum dilakukan validasi silang dan tidak terlihat adanya variasi kesalahan.\n",
        "\n",
        "- **Setelah Tuning:**  \n",
        "  - **Random Forest Cross-Validation Accuracy:** **1.0000 Â± 0.0000**  \n",
        "  - **XGBoost Cross-Validation Accuracy:** **0.9995 Â± 0.0010**  \n",
        "  - **Updated Random Forest Accuracy (Test Set):** **1.0**  \n",
        "  - **Updated XGBoost Accuracy (Test Set):** **0.9980**  \n",
        "\n",
        "> Setelah dilakukan tuning (termasuk pruning dan regularisasi), akurasi tetap berada di tingkat sangat tinggi. Hal ini dapat menandakan model memang sangat cocok dengan data, namun tetap perlu diwaspadai kemungkinan **overfitting ringan** atau **kompleksitas data yang rendah**.\n",
        "\n",
        "\n",
        "### **2. Identifikasi Kelemahan Model**  \n",
        "\n",
        "- **Overfitting (Minor):**  \n",
        "  - Akurasi yang sempurna pada Random Forest dan hampir sempurna pada XGBoost menunjukkan bahwa model mungkin **terlalu hafal terhadap data latih**, meskipun regularisasi sudah dilakukan.\n",
        "\n",
        "- **Kurangnya Variasi Error:**  \n",
        "  - Pada Random Forest, **tidak ada kesalahan klasifikasi sama sekali** (confusion matrix diagonal sempurna).  \n",
        "  - Pada XGBoost, hanya terjadi **1 kesalahan klasifikasi minor** pada kelas ke-3 (Cluster 2), mengindikasikan performa sangat kuat namun belum sepenuhnya generalisasi.\n",
        "\n",
        "- **Kemungkinan Data Mudah Diklasifikasi atau Tidak Seimbang:**  \n",
        "  - Hasil klasifikasi yang hampir sempurna bisa menjadi tanda bahwa **fitur sangat memisahkan antar kelas**, atau mungkin terdapat **feature leakage** atau **fitur dominan** yang terlalu kuat mempengaruhi hasil klasifikasi.\n",
        "\n",
        "\n",
        "### **3. Rekomendasi Tindakan Lanjutan**  \n",
        "\n",
        "1. **Tambah Variasi Dataset**  \n",
        "   - Perlu dilakukan penambahan data untuk mencakup **lebih banyak variasi kasus nyata**, terutama data dengan distribusi yang lebih seimbang atau kasus-kasus borderline.\n",
        "\n",
        "2. **Cek Potensi Data Leakage**  \n",
        "   - Pastikan tidak ada **informasi target yang secara tidak sengaja masuk ke fitur**, terutama jika data merupakan hasil transformasi atau penggabungan dari proses clustering sebelumnya.\n",
        "\n",
        "3. **Perkuat Regularisasi dan Kurangi Kompleksitas**  \n",
        "   - **Random Forest:**  \n",
        "     - Gunakan `max_depth` yang lebih kecil, seperti **5â€“8**, untuk membatasi kompleksitas pohon.  \n",
        "     - Gunakan `max_features='sqrt'` atau `max_features=0.5` untuk mengurangi korelasi antar pohon.  \n",
        "   - **XGBoost:**  \n",
        "     - Tambahkan `reg_alpha=0.5` (L1 regularization) untuk mengurangi kemungkinan overfit.  \n",
        "     - Gunakan `subsample=0.8` dan `colsample_bytree=0.8` untuk memperkenalkan variasi antar pohon.\n",
        "\n",
        "4. **Feature Engineering Lanjutan**  \n",
        "   - Analisis **feature importance** dan gunakan **SHAP analysis** untuk mengevaluasi kontribusi tiap fitur.  \n",
        "   - Pertimbangkan untuk menggunakan **Principal Component Analysis (PCA)** atau melakukan **filtering fitur yang saling berkorelasi tinggi**.\n",
        "\n",
        "5. **Bandingkan dengan Model Sederhana**  \n",
        "   - Lakukan uji pembanding dengan **Logistic Regression** atau **Decision Tree sederhana**. Jika hasilnya tetap tinggi, ini dapat mengonfirmasi bahwa **dataset mudah dipisahkan**.\n",
        "\n",
        "\n",
        "### **Kesimpulan**  \n",
        "Model Random Forest dan XGBoost berhasil mencapai **performansi klasifikasi yang nyaris sempurna** baik sebelum maupun setelah tuning. Namun, ketepatan yang terlalu tinggi ini bisa menjadi sinyal adanya **overfitting ringan** atau bahwa data tersebut **terlalu mudah dipelajari oleh model**.  \n",
        "Langkah-langkah lanjutan seperti menambah variasi data, memverifikasi tidak adanya data leakage, memperkuat regularisasi, dan mencoba model yang lebih sederhana perlu dilakukan agar model yang dibangun dapat **berkinerja optimal saat diterapkan ke data dunia nyata**."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
